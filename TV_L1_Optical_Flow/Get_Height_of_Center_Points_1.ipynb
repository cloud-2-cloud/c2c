{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNR-jJoNXXZq"
   },
   "source": [
    "#### Mount Drive, Copy CV2 Cuda Version, Enable CUDA, Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40494,
     "status": "ok",
     "timestamp": 1733508195552,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "9QEzsD9CU8g5",
    "outputId": "20361a29-7d03-4aff-eaf1-82bdca1ace42"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ## next time, load it into your work folder:\n",
    "# ## dont forget to restart the runtime, so it forgets about the old version !\n",
    "!cp \"/content/drive/My Drive/NASA/cv2_cuda_test/cv2.cpython-310-x86_64-linux-gnu.so\" .\n",
    "\n",
    "%cd /content/drive/MyDrive/NASA\n",
    "\n",
    "import cv2\n",
    "count = cv2.cuda.getCudaEnabledDeviceCount()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4114,
     "status": "ok",
     "timestamp": 1733507184302,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "7yizprckm3pR",
    "outputId": "d802090e-f405-477b-b7b7-c591f407c3c0"
   },
   "outputs": [],
   "source": [
    "!pip install azure-storage-blob azure-identity --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "R6kCr5dsnPF_"
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "# import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "import io\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from google.colab import userdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pad_packed_sequence, pack_padded_sequence, PackedSequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-rAqq6VPnWh_"
   },
   "outputs": [],
   "source": [
    "connection_string = \"Add connection string\"\n",
    "\n",
    "# Setup to load file from blob\n",
    "blob_service_client = \"Create Blob Service Client\"\n",
    "container_client = \"Create Container Client\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tic6Wjz2XuB1"
   },
   "source": [
    "#### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "UyGzL4uanfMn"
   },
   "outputs": [],
   "source": [
    "# aircraft_metadata_params = ['DateTime_UTC', 'GPS_MSL_Alt', 'Drift', 'Pitch', 'Roll', 'Vert_Velocity']\n",
    "\n",
    "aircraft_metadata_params = [\n",
    "    'DateTime_UTC', 'Lat', 'Lon', 'GPS_MSL_Alt', 'WGS_84_Alt', 'Press_Alt',\n",
    "    'Grnd_Spd', 'True_Airspeed', 'Mach_Number', 'Vert_Velocity', 'True_Hdg',\n",
    "    'Track', 'Drift', 'Pitch', 'Roll', 'Ambient_Temp', 'Total_Temp',\n",
    "    'Static_Press', 'Dynamic_Press', 'Cabin_Pressure', 'Wind_Speed',\n",
    "    'Wind_Dir', 'Solar_Zenith', 'Sun_Elev_AC', 'Sun_Az_Grd', 'Sun_Az_AC'\n",
    "]\n",
    "\n",
    "CTH_col = 'top_height'\n",
    "\n",
    "# Aircraft Metadata\n",
    "def load_metadata(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    streamdownloader = blob_client.download_blob()\n",
    "    metadata_df = pd.read_csv(io.BytesIO(streamdownloader.readall()))\n",
    "    return metadata_df\n",
    "\n",
    "# LiDAR Validation Heights\n",
    "def load_validation_heights(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    streamdownloader = blob_client.download_blob()\n",
    "    validation_df = pd.read_csv(io.BytesIO(streamdownloader.readall()))\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs6CM3aWXvII"
   },
   "source": [
    "##### Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "xCnYPu1tnqPz"
   },
   "outputs": [],
   "source": [
    "# CloudDataset classes integrating all 3 data sources: FEGS Images, Aircraft Metadata and LiDAR Validation Heights with temporal alignment\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, date_folders, transform=None, drop_after_last_validation=True):\n",
    "        self.date_folders = date_folders\n",
    "        self.transform = transform\n",
    "        self.drop_after_last_validation = drop_after_last_validation\n",
    "        self.data_df = self._prepare_dataframe()\n",
    "\n",
    "    def _prepare_dataframe(self):\n",
    "        \"\"\"\n",
    "        Iterates over the date folders in azure blob storage and loads:\n",
    "          1. .jpg Images from each sub-directory in the folder with '_crop_corrected_aligned' in the name.\n",
    "          2. Aircraft Metadata with 1-1 time alignment with the images.\n",
    "          3. LiDAR Validation Heights, mapped using timestamp, if not available filled with NaN.\n",
    "        Creates a df with following columns:\n",
    "            timestamp, image_path, [...aircraft_metadata_params...], validation_height\n",
    "        \"\"\"\n",
    "        image_paths, timestamps, metadata_rows, validation_heights = [], [], [], []\n",
    "\n",
    "        for folder in self.date_folders:\n",
    "            print(f\"Processing folder: {folder}\")\n",
    "            folder_image_paths, folder_timestamps, folder_metadata_rows, folder_validation_heights = [], [], [], []\n",
    "\n",
    "            blob_list = container_client.list_blobs(name_starts_with=folder)\n",
    "            metadata_path, validation_path = None, None\n",
    "            for blob in blob_list:\n",
    "                # extract image paths of all .jpg images in cropped folders\n",
    "                # if blob.name.endswith(\".jpg\") and \"_crop_corrected_aligned\" in blob.name:\n",
    "                if blob.name.endswith(\".jpg\") and \"_frames\" in blob.name in blob.name:\n",
    "                    folder_image_paths.append(blob.name)\n",
    "                    folder_timestamps.append(self._extract_timestamp_from_filename(blob.name))\n",
    "                # extract the aircraft metadata file path\n",
    "                if blob.name.startswith(f\"{folder}/IWG1.\") and \"processed\" in blob.name:\n",
    "                    metadata_path = blob.name\n",
    "                # extract the LiDAR validation file path\n",
    "                if blob.name.startswith(f\"{folder}/goesrplt_CPL_layers_\") and blob.name.endswith(\"_processed.txt\"):\n",
    "                    validation_path = blob.name\n",
    "\n",
    "            # load aircraft metadata and LiDAR validation data\n",
    "            if metadata_path:\n",
    "                metadata_df = load_metadata(metadata_path)\n",
    "            if validation_path:\n",
    "                validation_df = load_validation_heights(validation_path)\n",
    "\n",
    "            # prepare LiDAR validation data\n",
    "            validation_df['datetime_combined'] = validation_df['date'] + ' ' + validation_df['timestamp']\n",
    "            validation_df['datetime_combined'] = validation_df['datetime_combined'].str.split('.').str[0]\n",
    "            validation_df['datetime_combined'] = pd.to_datetime(validation_df['datetime_combined'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # prepare aircraft metadata\n",
    "            metadata_df = metadata_df[aircraft_metadata_params]\n",
    "            metadata_df['DateTime_UTC'] = metadata_df['DateTime_UTC'].str.split('.').str[0]\n",
    "            metadata_df = self._extract_time_features(metadata_df)  # Add hour_of_day and day_of_year\n",
    "\n",
    "            metadata_timestamps = pd.to_datetime(metadata_df['DateTime_UTC'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "            metadata_df = metadata_df.set_index(metadata_timestamps)\n",
    "            aligned_metadata = pd.DataFrame(index=pd.to_datetime(folder_timestamps, format=\"%H:%M:%S\"))\n",
    "            aligned_metadata = aligned_metadata.join(metadata_df, how='left')\n",
    "            aligned_metadata = aligned_metadata[aircraft_metadata_params + ['hour_of_day', 'day_of_year']]\n",
    "\n",
    "            folder_metadata_rows.extend(aligned_metadata.values.tolist())\n",
    "\n",
    "            # extract LiDAR validation height exactly matching the timestamp where available, else NaN\n",
    "            for ts in folder_timestamps:\n",
    "                cth = self._map_timestamp_to_lidar(ts, validation_df)\n",
    "                folder_validation_heights.append(cth)\n",
    "\n",
    "            # Create a folder-level DataFrame\n",
    "            folder_data = {\n",
    "                'timestamp': folder_timestamps,\n",
    "                'image_path': folder_image_paths,\n",
    "                **{param: [row[i] for row in folder_metadata_rows] for i, param in enumerate(aircraft_metadata_params + ['hour_of_day', 'day_of_year'])},\n",
    "                'validation_height': folder_validation_heights\n",
    "            }\n",
    "            folder_df = pd.DataFrame(folder_data)\n",
    "\n",
    "            # Conditionally remove rows after the last valid validation_height in this folder\n",
    "            if self.drop_after_last_validation:\n",
    "                last_valid_index = folder_df['validation_height'].last_valid_index()\n",
    "                if last_valid_index is not None:\n",
    "                    folder_df_cleaned = folder_df.loc[:last_valid_index].copy()  # Use .copy() to ensure independence\n",
    "                else:\n",
    "                    folder_df_cleaned = folder_df.copy()  # In case there are no valid entries\n",
    "            else:\n",
    "                folder_df_cleaned = folder_df  # Keep all rows if dropping is disabled\n",
    "\n",
    "            # Extend to the global lists\n",
    "            image_paths.extend(folder_df_cleaned['image_path'].tolist())\n",
    "            timestamps.extend(folder_df_cleaned['timestamp'].tolist())\n",
    "            metadata_rows.extend(folder_df_cleaned[aircraft_metadata_params + ['hour_of_day', 'day_of_year']].values.tolist())\n",
    "            validation_heights.extend(folder_df_cleaned['validation_height'].tolist())\n",
    "\n",
    "            # Print the lengths for the current folder\n",
    "            print(f\"Folder {folder}:\")\n",
    "            print(f\"  Number of images: {len(folder_df_cleaned['image_path'])}\")\n",
    "            print(f\"  Number of timestamps: {len(folder_df_cleaned['timestamp'])}\")\n",
    "            print(f\"  Number of metadata rows: {len(folder_df_cleaned)}\")\n",
    "            print(f\"  Number of validation heights: {len(folder_df_cleaned['validation_height'])}\")\n",
    "\n",
    "        # Print the final lengths after processing all folders\n",
    "        print(\"After processing all folders combined:\")\n",
    "        print(f\"  Total number of images: {len(image_paths)}\")\n",
    "        print(f\"  Total number of timestamps: {len(timestamps)}\")\n",
    "        print(f\"  Total number of metadata rows: {len(metadata_rows)}\")\n",
    "        print(f\"  Total number of validation heights: {len(validation_heights)}\")\n",
    "\n",
    "        # Check for any mismatches\n",
    "        if not (len(image_paths) == len(timestamps) == len(metadata_rows) == len(validation_heights)):\n",
    "            print(\"Error: Length mismatch detected!\")\n",
    "            print(f\"  Images: {len(image_paths)}\")\n",
    "            print(f\"  Timestamps: {len(timestamps)}\")\n",
    "            print(f\"  Metadata rows: {len(metadata_rows)}\")\n",
    "            print(f\"  Validation heights: {len(validation_heights)}\")\n",
    "            return None\n",
    "\n",
    "        # combine all aligned data in a df\n",
    "        data = {\n",
    "            'timestamp': timestamps,\n",
    "            'image_path': image_paths,\n",
    "            **{param: [row[i] for row in metadata_rows] for i, param in enumerate(aircraft_metadata_params + ['hour_of_day', 'day_of_year'])},\n",
    "            'validation_height': validation_heights\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.drop(columns=['DateTime_UTC'])\n",
    "\n",
    "        # Print columns with NaN values before interpolation\n",
    "        self._print_columns_with_nan(df)\n",
    "\n",
    "        # Interpolate missing values, excluding 'validation_height'\n",
    "        df = self._interpolate_missing_values(df)\n",
    "\n",
    "        # Add sequence length information for RNN\n",
    "        self._add_sequence_length_column(df)\n",
    "        return df\n",
    "\n",
    "    def _extract_time_features(self, df):\n",
    "        \"\"\"\n",
    "        Extracts hour of day and day of year from the DateTime_UTC column.\n",
    "        Adds 'hour_of_day' (with fractional hour) and 'day_of_year' as new columns in the DataFrame.\n",
    "        \"\"\"\n",
    "        df['DateTime_UTC'] = pd.to_datetime(df['DateTime_UTC'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        df['hour_of_day'] = df['DateTime_UTC'].dt.hour + df['DateTime_UTC'].dt.minute / 60\n",
    "        df['day_of_year'] = df['DateTime_UTC'].dt.dayofyear\n",
    "        return df\n",
    "\n",
    "    def _extract_timestamp_from_filename(self, filename):\n",
    "        \"\"\"\n",
    "        Extracts the timestamp from the image filename on the blob.\n",
    "        path/to/blob/YYYYMMDD_HHMMSS_frame_n_cropped.jpg -> %Y%m%d%H%M%S\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filename)\n",
    "        date_str = filename.split(\"_\")[0]\n",
    "        time_str = filename.split(\"_\")[1]\n",
    "        timestamp = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "        return timestamp\n",
    "\n",
    "\n",
    "    def _map_timestamp_to_lidar(self, timestamp, validation_df):\n",
    "        \"\"\"\n",
    "        extract LiDAR validation height exactly matching the timestamp where available, else NaN\n",
    "        \"\"\"\n",
    "        validation_df['datetime_combined'] = pd.to_datetime(validation_df['datetime_combined'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        timestamp_dt = pd.to_datetime(timestamp, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        exact_match = validation_df[validation_df['datetime_combined'] == timestamp_dt]\n",
    "        return exact_match[CTH_col].values[0] if not exact_match.empty else np.nan\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a data record from the dataset for a given index.\n",
    "        Returns loaded and transformed image, metadata and validation height associated with that image if available.\n",
    "        \"\"\"\n",
    "        row = self.data_df.iloc[idx]\n",
    "\n",
    "        image_path = row['image_path']\n",
    "        blob_client = container_client.get_blob_client(image_path)\n",
    "        streamdownloader = blob_client.download_blob()\n",
    "        img_data = streamdownloader.readall()\n",
    "        img = Image.open(io.BytesIO(img_data)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        metadata = torch.tensor([row[param] for param in aircraft_metadata_params], dtype=torch.float32)\n",
    "        validation_height = torch.tensor([row['validation_height']], dtype=torch.float32)\n",
    "\n",
    "        return img, metadata, validation_height\n",
    "\n",
    "    def _add_sequence_length_column(self, df):\n",
    "        # Initialize a new column to NaN\n",
    "        df['sequence_length'] = np.nan\n",
    "\n",
    "        # Track the start of each sequence\n",
    "        sequence_start = 0\n",
    "\n",
    "        # Iterate through the dataframe to detect when a validation_height exists\n",
    "        for i in range(len(df)):\n",
    "            if not pd.isna(df.loc[i, 'validation_height']):\n",
    "                # We found the end of a sequence, so mark the previous sequence images\n",
    "                sequence_length = i - sequence_start\n",
    "                df.loc[sequence_start:i, 'sequence_length'] = sequence_length + 1  # Using count (1-based index)\n",
    "                sequence_start = i + 1  # Move the start to the next sequence\n",
    "\n",
    "        # Ensure all sequence_length values are integers (if any were missed)\n",
    "        df['sequence_length'] = df['sequence_length'].astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _print_columns_with_nan(self, df):\n",
    "        \"\"\"\n",
    "        Prints the names of columns in the DataFrame that contain NaN values.\n",
    "        \"\"\"\n",
    "        columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "        if columns_with_nan:\n",
    "            print(\"Columns with NaN values:\")\n",
    "            for col in columns_with_nan:\n",
    "                print(col)\n",
    "        else:\n",
    "            print(\"No columns with NaN values.\")\n",
    "\n",
    "    def _interpolate_missing_values(self, df, exclude_columns=['validation_height', 'timestamp', 'image_path']):\n",
    "        \"\"\"\n",
    "        Interpolates missing values in the DataFrame for all columns except specified ones.\n",
    "        \"\"\"\n",
    "        # Create a copy to avoid modifying the original DataFrame\n",
    "        df = df.copy()\n",
    "\n",
    "        # Store excluded columns\n",
    "        excluded_data = {col: df[col].copy() for col in exclude_columns if col in df.columns}\n",
    "\n",
    "        # Convert all object-type columns in df to numeric where possible\n",
    "        df = df.infer_objects()\n",
    "\n",
    "        # Get columns for interpolation (excluding specified columns)\n",
    "        columns_to_interpolate = [col for col in df.columns if col not in exclude_columns]\n",
    "\n",
    "        # Convert columns to numeric where possible\n",
    "        for col in columns_to_interpolate:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "        # Perform interpolation only on numeric columns\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if not numeric_columns.empty:\n",
    "            df[numeric_columns] = df[numeric_columns].interpolate(\n",
    "                method='linear',\n",
    "                axis=0,\n",
    "                limit_direction='both'\n",
    "            )\n",
    "\n",
    "        # Restore excluded columns\n",
    "        for col, data in excluded_data.items():\n",
    "            df[col] = data\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tri_eM8_XzNF"
   },
   "source": [
    "##### Insantiating the data class, loading the data and saving the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "jz1SC3cQn2Th"
   },
   "outputs": [],
   "source": [
    "# train_dates = [\"60fps_v1/20170418\"]\n",
    "\n",
    "# # Change the cache_cloud_dataset variable at the start to make this either\n",
    "# # generate the CloudDataset (takes some time) or use a cached version on Google Drive.\n",
    "\n",
    "# full_dataset = CloudDataset(train_dates, transform=None)\n",
    "# # Extract the full dataframe from CloudDataset\n",
    "# full_dataframe = full_dataset.data_df\n",
    "# # Ensure folder exists\n",
    "# os.makedirs('yash_datasets', exist_ok=True)\n",
    "# # Save the dataframe directly to Google Drive\n",
    "# full_dataframe.to_csv('yash_datasets/train_dataset.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6_dbqN4vglhx"
   },
   "outputs": [],
   "source": [
    "full_dataframe = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1733507195719,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "s0WxR02rpLCq",
    "outputId": "4c4c9547-ffab-4445-dc49-ac06ce0f44b7"
   },
   "outputs": [],
   "source": [
    "full_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "nza0ZUvp1oas"
   },
   "outputs": [],
   "source": [
    "inputs = full_dataframe.drop_duplicates('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1733507195719,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "v8FLPlSl3dNS",
    "outputId": "505cb344-1d81-43cb-d818-55658248e67b"
   },
   "outputs": [],
   "source": [
    "inputs.dropna(subset=['validation_height'], inplace=True)\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TU0Nt9kWX8a5"
   },
   "source": [
    "#### Helper functions for image loading, fisheye correction and cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NVp7o9_23j2z"
   },
   "outputs": [],
   "source": [
    "def load_image_from_blob_cv(blob_img, container_client):\n",
    "    \"\"\"\n",
    "    Loads the image from Azure Blob Storage using OpenCV and returns it as a numpy array.\n",
    "    Args:\n",
    "        blob_img (str): name of the blob image in the container\n",
    "        container_client (azure.storage.blob.BlobContainerClient): container client\n",
    "    Returns:\n",
    "        (numpy.ndarray): loaded image with original channels retained\n",
    "    \"\"\"\n",
    "    blob_client = container_client.get_blob_client(blob_img)\n",
    "    streamdownloader = blob_client.download_blob()\n",
    "    blob_data = streamdownloader.readall()\n",
    "    image_array = np.asarray(bytearray(blob_data), dtype=np.uint8)\n",
    "    # img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    img_bgr = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "def undistort_fisheye_image(distorted_image):\n",
    "    \"\"\"\n",
    "    Apply correction for fisheye distortion.\n",
    "    Args:\n",
    "        distorted_image (numpy.ndarray): original image that has the fisheye distortion.\n",
    "     Returns:\n",
    "        (numpy.ndarray): undistorted image with fisheye correction.\n",
    "    \"\"\"\n",
    "    # Parameters provided\n",
    "    f = 1.4  # focal length [mm]\n",
    "    mu = 2.8e-3  # pixel pitch [mm]\n",
    "    S = 2  # output (undistorted) image scale factor\n",
    "    # distortion polynomial order:  [2 4 6 8]\n",
    "    # polynomial coefficients:\n",
    "    coeffs = np.array([0.01166363, -0.04819808, 0.07918044, -0.037572])\n",
    "\n",
    "    H = distorted_image.shape[0]  # image height [pixel]\n",
    "    W = distorted_image.shape[1]  # image width [pixel]\n",
    "    cx = (W - 1) / 2  # image center coordinate [pixel]\n",
    "    cy = (H - 1) / 2  # image center coordinate [pixel]\n",
    "\n",
    "    K = np.array([[f / mu, 0, cx], [0, f / mu, cy], [0, 0, 1]])\n",
    "\n",
    "    # compute intrinsic matrix for undistorted image\n",
    "    cpx = (W * S - 1) / 2\n",
    "    cpy = (H * S - 1) / 2\n",
    "    P = np.array([[f / mu, 0, cpx], [0, f / mu, cpy], [0, 0, 1]])\n",
    "\n",
    "    # rectification matrix (identity)\n",
    "    R = np.eye(3)\n",
    "\n",
    "    # produce undistorted image\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K=K, D=coeffs, R=R, P=P, size=[W * S, H * S], m1type=cv2.CV_16SC2)\n",
    "    undistorted_image = cv2.remap(distorted_image, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    return undistorted_image\n",
    "\n",
    "def crop_and_correct_image_cv2(image, size1=(1500, 1500), offset=(85, 180), size2=(800, 800)):\n",
    "    \"\"\"\n",
    "    Crops the undistorted image in two stages and ensures the original center (960, 540)\n",
    "    aligns with the center of the final cropped image (400, 400).\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image to crop.\n",
    "        size1 (tuple): Size of the first crop (width, height).\n",
    "        offset (tuple): Offset for the first crop.\n",
    "        size2 (tuple): Size of the final crop (width, height).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Cropped image.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Step 1: First crop with offset\n",
    "    center_h, center_w = h // 2, w // 2  # Center of the undistorted image\n",
    "    offset_h, offset_w = offset\n",
    "\n",
    "    # Adjust the starting coordinates for the first crop\n",
    "    start_h1 = max(center_h - size1[1] // 2 + offset_h, 0)\n",
    "    start_w1 = max(center_w - size1[0] // 2 + offset_w, 0)\n",
    "    cropped_image = image[start_h1:start_h1 + size1[1], start_w1:start_w1 + size1[0]]\n",
    "\n",
    "    # Step 2: Adjust second crop to ensure the original center aligns with the center of the crop-corrected image\n",
    "    crop_h, crop_w = size2\n",
    "    center_h_crop = center_h - start_h1  # Adjusted center in the cropped image\n",
    "    center_w_crop = center_w - start_w1\n",
    "\n",
    "    # Calculate start coordinates to place the center at 400, 400\n",
    "    start_h2 = max(center_h_crop - crop_h // 2, 0)\n",
    "    start_w2 = max(center_w_crop - crop_w // 2, 0)\n",
    "\n",
    "    final_image = cropped_image[start_h2:start_h2 + crop_h, start_w2:start_w2 + crop_w]\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFWt1Ln5YDWI"
   },
   "source": [
    "#### Optical flow related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "usol-nRUpmDH"
   },
   "outputs": [],
   "source": [
    "def get_H_W(inputs, first_frame):\n",
    "  img_stream = load_image_from_blob_cv(inputs['image_path'][first_frame], container_client)\n",
    "  H, W = img_stream.shape[:2]\n",
    "  return H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "M5PF6Nf8_3v9"
   },
   "outputs": [],
   "source": [
    "def get_next(inputs, first_frame, x, y):\n",
    "    #img1 = cv2.imread(image_folder + 'frame%d.jpg' % first_frame, cv2.IMREAD_GRAYSCALE)\n",
    "    img_stream = load_image_from_blob_cv(inputs['image_path'][first_frame], container_client)\n",
    "    # fisheye_corrected_img = undistort_fisheye_image(img_stream)\n",
    "    # cropped_img = crop_and_correct_image_cv2(fisheye_corrected_img)\n",
    "    cropped_img = img_stream\n",
    "    # cropped_img = cropped_img[200:600, 200:600]\n",
    "    img1 = cv2.cvtColor(cropped_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    for i in range(first_frame+1,131000):\n",
    "        #img2 = cv2.imread(image_folder + 'frame%d.jpg' % int(i+1), cv2.IMREAD_GRAYSCALE)\n",
    "        img_stream = load_image_from_blob_cv(inputs['image_path'][i+1], container_client)\n",
    "        # fisheye_corrected_img = undistort_fisheye_image(img_stream)\n",
    "        # cropped_img = crop_and_correct_image_cv2(fisheye_corrected_img)\n",
    "        cropped_img = img_stream\n",
    "        # cropped_img = cropped_img[200:600, 200:600]\n",
    "        #cropped_img = cropped_img[240:840, 660:1260]\n",
    "        img2 = cv2.cvtColor(cropped_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # optical_flow = cv2.optflow.createOptFlow_DualTVL1()\n",
    "        cuMat1 = cv2.cuda_GpuMat()\n",
    "        cuMat2 = cv2.cuda_GpuMat()\n",
    "        cuMat1.upload(img1)\n",
    "        cuMat2.upload(img2)\n",
    "        optical_flow_cuda = cv2.cuda.OpticalFlowDual_TVL1_create()\n",
    "        # optical_flow_cuda.setWarpingsNumber(1)\n",
    "\n",
    "        # flow = optical_flow_cuda.calc(img1,img2, None)\n",
    "        cu_flow = optical_flow_cuda.calc(cuMat1, cuMat2, None)\n",
    "        optical_flow_data = cu_flow.download()\n",
    "\n",
    "        v = optical_flow_data[x, y, 0]\n",
    "        u = optical_flow_data[x, y, 1]\n",
    "\n",
    "        if u>=1 or abs(v)>=0.5:\n",
    "            #print(i, u, v, x, y)\n",
    "            break\n",
    "\n",
    "        #warps=1, scales=0.5, tau=0.25\n",
    "    return i,u,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "3b4oJTqhAzvO"
   },
   "outputs": [],
   "source": [
    "def get_OF(inputs, first_frame, x, y):\n",
    "    change = 0\n",
    "    first_frame_org = first_frame\n",
    "\n",
    "    #try:\n",
    "    while first_frame<first_frame_org+300 and x<1000 and change<50:\n",
    "        old_frame = first_frame\n",
    "        first_frame, u, v = get_next(inputs, first_frame, x, y)\n",
    "        if u>=1:\n",
    "            x = x + round(u)\n",
    "        if abs(v)>=0.5:\n",
    "            y = y + round(v)\n",
    "        change = first_frame - old_frame\n",
    "    #except:\n",
    "        #print(\"error\")\n",
    "        #pass\n",
    "\n",
    "    return x, y, first_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2uws7gJWA3VS"
   },
   "outputs": [],
   "source": [
    "def get_speed(mu, first_pixel, last_pixel, first_frame, last_frame):\n",
    "    travelled_pixels = last_pixel - first_pixel\n",
    "    travel_time = (last_frame - first_frame)/60\n",
    "\n",
    "    travelled_distance = travelled_pixels * mu\n",
    "    #print(travelled_pixels, travelled_distance, travel_time)\n",
    "    u = travelled_distance/travel_time\n",
    "\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k2EVjIRQA7k_"
   },
   "outputs": [],
   "source": [
    "def Get_Ground_Point(x, y, cx, cy, h, g, mu, f):\n",
    "    x1 = x-cx\n",
    "    y1 = y-cy\n",
    "\n",
    "    d1 = (g-h)*x1*mu/f\n",
    "    d2 = (g-h)*y1*mu/f\n",
    "\n",
    "    return d1, d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ry6r-QKsA-nP"
   },
   "outputs": [],
   "source": [
    "def Get_center_distance(lat1, lat2, lon1, lon2):\n",
    "    lon1 = radians(lon1)\n",
    "    lon2 = radians(lon2)\n",
    "    lat1 = radians(lat1)\n",
    "    lat2 = radians(lat2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371\n",
    "    return(c * r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "r6mPpcq8lwq7"
   },
   "outputs": [],
   "source": [
    "def get_undistorted_endpoints(mu, S, H, W, x, y):\n",
    "    cx = (W-1)/2        # image center coordinate [pixel]\n",
    "    cy = (H-1)/2        # image center coordinate [pixel]\n",
    "\n",
    "    K = np.array([[f/mu,0,cx],[0,f/mu,cy],[0,0,1]])\n",
    "\n",
    "    # compute intrinsic matrix for ouput image\n",
    "    cpx = (W*S-1)/2\n",
    "    cpy = (H*S-1)/2\n",
    "    P = np.array([[f/mu,0,cpx],[0,f/mu,cpy],[0,0,1]])\n",
    "\n",
    "    D = np.array([0.01166363, -0.04819808, 0.07918044, -0.037572])\n",
    "\n",
    "    R = np.eye(3)\n",
    "\n",
    "    coord_homog = np.array([x, y, 1.0], dtype=np.float32).reshape(-1, 1)\n",
    "    undistorted_coord = cv2.fisheye.undistortPoints(\n",
    "        coord_homog.T[:, :2].reshape(1, -1, 2),\n",
    "        K=K, D=D, R=R, P=P\n",
    "    )[0][0]\n",
    "    x_1, y_1 = undistorted_coord\n",
    "\n",
    "    return x_1, y_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecoSr5owYLmj"
   },
   "source": [
    "#### Running the optical flow method for the center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Iuc1JA_kBBCN"
   },
   "outputs": [],
   "source": [
    "diam = 7.6\n",
    "frame_pixels = 1082\n",
    "mu = 7.6/1082\n",
    "f = 1.4\n",
    "mu_1 = 2.8e-3\n",
    "S = 2\n",
    "# x = 200\n",
    "# y = 200\n",
    "x = 540\n",
    "y = 960\n",
    "\n",
    "H, W = get_H_W(full_dataframe, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RQ0_uLiIBEuf"
   },
   "outputs": [],
   "source": [
    "#inputs['Estimated height'] = \"\"\n",
    "#inputs['Diff'] = \"\"\n",
    "#inputs['Speed'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4430531,
     "status": "error",
     "timestamp": 1733521204888,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "-TgPhE-IBMl5",
    "outputId": "a235598e-7427-42bc-ae8c-613cd3298409"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "cnt = 0\n",
    "\n",
    "for ind in tqdm(inputs.index):\n",
    "    st = time.time()\n",
    "    if ind >= 56640:\n",
    "        #print(datetime.now(), ind)\n",
    "\n",
    "        x_l, y_l, frame_l = get_OF(full_dataframe, ind, x, y)\n",
    "\n",
    "        t = y\n",
    "        if y_l<y:\n",
    "            y = y_l\n",
    "            y_l = t\n",
    "\n",
    "        k_1, k = get_undistorted_endpoints(mu_1, S, H, W, y, x)\n",
    "        m_1, m = get_undistorted_endpoints(mu_1, S, H, W, y_l, x_l)\n",
    "\n",
    "        u = get_speed(mu, k, m, ind, frame_l)\n",
    "\n",
    "\n",
    "        #print(f\"Coordinates: {x}, {x_l}\")\n",
    "\n",
    "        if u != 0:\n",
    "            height = (inputs['GPS_MSL_Alt'][ind] - f*inputs['Grnd_Spd'][ind]/u)*math.cos(math.pi*inputs['Pitch'][ind]/180)\n",
    "        else:\n",
    "            height = 0\n",
    "\n",
    "        inputs.loc[ind, \"Estimated height\"] = round(height)\n",
    "        inputs.loc[ind, \"Diff\"] = abs(inputs['validation_height'][ind] - round(height))\n",
    "        inputs.loc[ind, \"Speed\"] = u\n",
    "\n",
    "        if cnt % 25 == 0:\n",
    "            inputs.to_csv(\"Center_Points_2.csv\")\n",
    "\n",
    "        cnt - cnt + 1\n",
    "        print(ind, f\"Time Taken in s: {time.time() - st}\", f\"Height Estimated: {height}\")\n",
    "        #print(f\"Time Taken in s: {time.time() - st}\")\n",
    "\n",
    "inputs.to_csv(\"Center_Points_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1733521226590,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "5a16my76cBMD"
   },
   "outputs": [],
   "source": [
    "inputs.to_csv(\"Center_Points_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "aborted",
     "timestamp": 1733521204891,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "scVdh23nCQWY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1CLU9hDdogpoMyyziRoMtHJC3zRQ8Xurd",
     "timestamp": 1732861859187
    },
    {
     "file_id": "155m9Ch_DSq5K2bYNMlCpiABrJKfVVVyP",
     "timestamp": 1732856959674
    },
    {
     "file_id": "1qqrVlgCcauJlYhFulALDDjZS2s-FcR9c",
     "timestamp": 1732796564926
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
