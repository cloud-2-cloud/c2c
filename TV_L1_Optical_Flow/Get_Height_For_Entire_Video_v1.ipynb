{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34445,
     "status": "ok",
     "timestamp": 1733432382399,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "_-E-NsxXcHQR",
    "outputId": "29bce378-532b-499a-9d67-e116ba4a4d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/.shortcut-targets-by-id/1AM28lxL021WtA9_4-YXcChNOcijk4IBJ/NASA\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ## next time, load it into your work folder:\n",
    "# ## dont forget to restart the runtime, so it forgets about the old version !\n",
    "!cp \"/content/drive/My Drive/NASA/cv2_cuda_test/cv2.cpython-310-x86_64-linux-gnu.so\" .\n",
    "\n",
    "%cd /content/drive/MyDrive/NASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733432382399,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "UE9-SV2JdTLd",
    "outputId": "bcf5908b-a98f-4a4d-faf2-3f3045997d89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "count = cv2.cuda.getCudaEnabledDeviceCount()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5982,
     "status": "ok",
     "timestamp": 1733432388378,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "qNNlse5LdhNj",
    "outputId": "cfdb72ab-7f15-4e7f-d6ae-b45b06e63f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.2/113.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install azure-storage-blob azure-identity --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYWKrqVBdlal"
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from numpy import inf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import io\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "from google.colab import userdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pad_packed_sequence, pack_padded_sequence, PackedSequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwqe-IaEdsED"
   },
   "outputs": [],
   "source": [
    "connection_string = \"Add connection string\"\n",
    "\n",
    "# Setup to load file from blob\n",
    "blob_service_client = \"Create Blob Service Client\"\n",
    "container_client = \"Create Container Client\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9hT0XyDd5cS"
   },
   "source": [
    "#### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N8ize-Moduv2"
   },
   "outputs": [],
   "source": [
    "# aircraft_metadata_params = ['DateTime_UTC', 'GPS_MSL_Alt', 'Drift', 'Pitch', 'Roll', 'Vert_Velocity']\n",
    "\n",
    "aircraft_metadata_params = [\n",
    "    'DateTime_UTC', 'Lat', 'Lon', 'GPS_MSL_Alt', 'WGS_84_Alt', 'Press_Alt',\n",
    "    'Grnd_Spd', 'True_Airspeed', 'Mach_Number', 'Vert_Velocity', 'True_Hdg',\n",
    "    'Track', 'Drift', 'Pitch', 'Roll', 'Ambient_Temp', 'Total_Temp',\n",
    "    'Static_Press', 'Dynamic_Press', 'Cabin_Pressure', 'Wind_Speed',\n",
    "    'Wind_Dir', 'Solar_Zenith', 'Sun_Elev_AC', 'Sun_Az_Grd', 'Sun_Az_AC'\n",
    "]\n",
    "\n",
    "CTH_col = 'top_height'\n",
    "\n",
    "# Aircraft Metadata\n",
    "def load_metadata(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    streamdownloader = blob_client.download_blob()\n",
    "    metadata_df = pd.read_csv(io.BytesIO(streamdownloader.readall()))\n",
    "    return metadata_df\n",
    "\n",
    "# LiDAR Validation Heights\n",
    "def load_validation_heights(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    streamdownloader = blob_client.download_blob()\n",
    "    validation_df = pd.read_csv(io.BytesIO(streamdownloader.readall()))\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KyPJ9JoeDID"
   },
   "source": [
    "##### Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r_2ikXcbd4EJ"
   },
   "outputs": [],
   "source": [
    "# CloudDataset classes integrating all 3 data sources: FEGS Images, Aircraft Metadata and LiDAR Validation Heights with temporal alignment\n",
    "class CloudDataset(Dataset):\n",
    "    def __init__(self, date_folders, transform=None, drop_after_last_validation=True):\n",
    "        self.date_folders = date_folders\n",
    "        self.transform = transform\n",
    "        self.drop_after_last_validation = drop_after_last_validation\n",
    "        self.data_df = self._prepare_dataframe()\n",
    "\n",
    "    def _prepare_dataframe(self):\n",
    "        \"\"\"\n",
    "        Iterates over the date folders in azure blob storage and loads:\n",
    "          1. .jpg Images from each sub-directory in the folder with '_crop_corrected_aligned' in the name.\n",
    "          2. Aircraft Metadata with 1-1 time alignment with the images.\n",
    "          3. LiDAR Validation Heights, mapped using timestamp, if not available filled with NaN.\n",
    "        Creates a df with following columns:\n",
    "            timestamp, image_path, [...aircraft_metadata_params...], validation_height\n",
    "        \"\"\"\n",
    "        image_paths, timestamps, metadata_rows, validation_heights = [], [], [], []\n",
    "\n",
    "        for folder in self.date_folders:\n",
    "            print(f\"Processing folder: {folder}\")\n",
    "            folder_image_paths, folder_timestamps, folder_metadata_rows, folder_validation_heights = [], [], [], []\n",
    "\n",
    "            blob_list = container_client.list_blobs(name_starts_with=folder)\n",
    "            metadata_path, validation_path = None, None\n",
    "            for blob in blob_list:\n",
    "                # extract image paths of all .jpg images in cropped folders\n",
    "                # if blob.name.endswith(\".jpg\") and \"_crop_corrected_aligned\" in blob.name:\n",
    "                if blob.name.endswith(\".jpg\") and \"_frames\" in blob.name in blob.name:\n",
    "                    folder_image_paths.append(blob.name)\n",
    "                    folder_timestamps.append(self._extract_timestamp_from_filename(blob.name))\n",
    "                # extract the aircraft metadata file path\n",
    "                if blob.name.startswith(f\"{folder}/IWG1.\") and \"processed\" in blob.name:\n",
    "                    metadata_path = blob.name\n",
    "                # extract the LiDAR validation file path\n",
    "                if blob.name.startswith(f\"{folder}/goesrplt_CPL_layers_\") and blob.name.endswith(\"_processed.txt\"):\n",
    "                    validation_path = blob.name\n",
    "\n",
    "            # load aircraft metadata and LiDAR validation data\n",
    "            if metadata_path:\n",
    "                metadata_df = load_metadata(metadata_path)\n",
    "            if validation_path:\n",
    "                validation_df = load_validation_heights(validation_path)\n",
    "\n",
    "            # prepare LiDAR validation data\n",
    "            validation_df['datetime_combined'] = validation_df['date'] + ' ' + validation_df['timestamp']\n",
    "            validation_df['datetime_combined'] = validation_df['datetime_combined'].str.split('.').str[0]\n",
    "            validation_df['datetime_combined'] = pd.to_datetime(validation_df['datetime_combined'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # prepare aircraft metadata\n",
    "            metadata_df = metadata_df[aircraft_metadata_params]\n",
    "            metadata_df['DateTime_UTC'] = metadata_df['DateTime_UTC'].str.split('.').str[0]\n",
    "            metadata_df = self._extract_time_features(metadata_df)  # Add hour_of_day and day_of_year\n",
    "\n",
    "            metadata_timestamps = pd.to_datetime(metadata_df['DateTime_UTC'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "            metadata_df = metadata_df.set_index(metadata_timestamps)\n",
    "            aligned_metadata = pd.DataFrame(index=pd.to_datetime(folder_timestamps, format=\"%H:%M:%S\"))\n",
    "            aligned_metadata = aligned_metadata.join(metadata_df, how='left')\n",
    "            aligned_metadata = aligned_metadata[aircraft_metadata_params + ['hour_of_day', 'day_of_year']]\n",
    "\n",
    "            folder_metadata_rows.extend(aligned_metadata.values.tolist())\n",
    "\n",
    "            # extract LiDAR validation height exactly matching the timestamp where available, else NaN\n",
    "            for ts in folder_timestamps:\n",
    "                cth = self._map_timestamp_to_lidar(ts, validation_df)\n",
    "                folder_validation_heights.append(cth)\n",
    "\n",
    "            # Create a folder-level DataFrame\n",
    "            folder_data = {\n",
    "                'timestamp': folder_timestamps,\n",
    "                'image_path': folder_image_paths,\n",
    "                **{param: [row[i] for row in folder_metadata_rows] for i, param in enumerate(aircraft_metadata_params + ['hour_of_day', 'day_of_year'])},\n",
    "                'validation_height': folder_validation_heights\n",
    "            }\n",
    "            folder_df = pd.DataFrame(folder_data)\n",
    "\n",
    "            # Conditionally remove rows after the last valid validation_height in this folder\n",
    "            if self.drop_after_last_validation:\n",
    "                last_valid_index = folder_df['validation_height'].last_valid_index()\n",
    "                if last_valid_index is not None:\n",
    "                    folder_df_cleaned = folder_df.loc[:last_valid_index].copy()  # Use .copy() to ensure independence\n",
    "                else:\n",
    "                    folder_df_cleaned = folder_df.copy()  # In case there are no valid entries\n",
    "            else:\n",
    "                folder_df_cleaned = folder_df  # Keep all rows if dropping is disabled\n",
    "\n",
    "            # Extend to the global lists\n",
    "            image_paths.extend(folder_df_cleaned['image_path'].tolist())\n",
    "            timestamps.extend(folder_df_cleaned['timestamp'].tolist())\n",
    "            metadata_rows.extend(folder_df_cleaned[aircraft_metadata_params + ['hour_of_day', 'day_of_year']].values.tolist())\n",
    "            validation_heights.extend(folder_df_cleaned['validation_height'].tolist())\n",
    "\n",
    "            # Print the lengths for the current folder\n",
    "            print(f\"Folder {folder}:\")\n",
    "            print(f\"  Number of images: {len(folder_df_cleaned['image_path'])}\")\n",
    "            print(f\"  Number of timestamps: {len(folder_df_cleaned['timestamp'])}\")\n",
    "            print(f\"  Number of metadata rows: {len(folder_df_cleaned)}\")\n",
    "            print(f\"  Number of validation heights: {len(folder_df_cleaned['validation_height'])}\")\n",
    "\n",
    "        # Print the final lengths after processing all folders\n",
    "        print(\"After processing all folders combined:\")\n",
    "        print(f\"  Total number of images: {len(image_paths)}\")\n",
    "        print(f\"  Total number of timestamps: {len(timestamps)}\")\n",
    "        print(f\"  Total number of metadata rows: {len(metadata_rows)}\")\n",
    "        print(f\"  Total number of validation heights: {len(validation_heights)}\")\n",
    "\n",
    "        # Check for any mismatches\n",
    "        if not (len(image_paths) == len(timestamps) == len(metadata_rows) == len(validation_heights)):\n",
    "            print(\"Error: Length mismatch detected!\")\n",
    "            print(f\"  Images: {len(image_paths)}\")\n",
    "            print(f\"  Timestamps: {len(timestamps)}\")\n",
    "            print(f\"  Metadata rows: {len(metadata_rows)}\")\n",
    "            print(f\"  Validation heights: {len(validation_heights)}\")\n",
    "            return None\n",
    "\n",
    "        # combine all aligned data in a df\n",
    "        data = {\n",
    "            'timestamp': timestamps,\n",
    "            'image_path': image_paths,\n",
    "            **{param: [row[i] for row in metadata_rows] for i, param in enumerate(aircraft_metadata_params + ['hour_of_day', 'day_of_year'])},\n",
    "            'validation_height': validation_heights\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df.drop(columns=['DateTime_UTC'])\n",
    "\n",
    "        # Print columns with NaN values before interpolation\n",
    "        self._print_columns_with_nan(df)\n",
    "\n",
    "        # Interpolate missing values, excluding 'validation_height'\n",
    "        df = self._interpolate_missing_values(df)\n",
    "\n",
    "        # Add sequence length information for RNN\n",
    "        self._add_sequence_length_column(df)\n",
    "        return df\n",
    "\n",
    "    def _extract_time_features(self, df):\n",
    "        \"\"\"\n",
    "        Extracts hour of day and day of year from the DateTime_UTC column.\n",
    "        Adds 'hour_of_day' (with fractional hour) and 'day_of_year' as new columns in the DataFrame.\n",
    "        \"\"\"\n",
    "        df['DateTime_UTC'] = pd.to_datetime(df['DateTime_UTC'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        df['hour_of_day'] = df['DateTime_UTC'].dt.hour + df['DateTime_UTC'].dt.minute / 60\n",
    "        df['day_of_year'] = df['DateTime_UTC'].dt.dayofyear\n",
    "        return df\n",
    "\n",
    "    def _extract_timestamp_from_filename(self, filename):\n",
    "        \"\"\"\n",
    "        Extracts the timestamp from the image filename on the blob.\n",
    "        path/to/blob/YYYYMMDD_HHMMSS_frame_n_cropped.jpg -> %Y%m%d%H%M%S\n",
    "        \"\"\"\n",
    "        filename = os.path.basename(filename)\n",
    "        date_str = filename.split(\"_\")[0]\n",
    "        time_str = filename.split(\"_\")[1]\n",
    "        timestamp = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M%S\")\n",
    "        return timestamp\n",
    "\n",
    "\n",
    "    def _map_timestamp_to_lidar(self, timestamp, validation_df):\n",
    "        \"\"\"\n",
    "        extract LiDAR validation height exactly matching the timestamp where available, else NaN\n",
    "        \"\"\"\n",
    "        validation_df['datetime_combined'] = pd.to_datetime(validation_df['datetime_combined'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        timestamp_dt = pd.to_datetime(timestamp, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        exact_match = validation_df[validation_df['datetime_combined'] == timestamp_dt]\n",
    "        return exact_match[CTH_col].values[0] if not exact_match.empty else np.nan\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve a data record from the dataset for a given index.\n",
    "        Returns loaded and transformed image, metadata and validation height associated with that image if available.\n",
    "        \"\"\"\n",
    "        row = self.data_df.iloc[idx]\n",
    "\n",
    "        image_path = row['image_path']\n",
    "        blob_client = container_client.get_blob_client(image_path)\n",
    "        streamdownloader = blob_client.download_blob()\n",
    "        img_data = streamdownloader.readall()\n",
    "        img = Image.open(io.BytesIO(img_data)).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        metadata = torch.tensor([row[param] for param in aircraft_metadata_params], dtype=torch.float32)\n",
    "        validation_height = torch.tensor([row['validation_height']], dtype=torch.float32)\n",
    "\n",
    "        return img, metadata, validation_height\n",
    "\n",
    "    def _add_sequence_length_column(self, df):\n",
    "        # Initialize a new column to NaN\n",
    "        df['sequence_length'] = np.nan\n",
    "\n",
    "        # Track the start of each sequence\n",
    "        sequence_start = 0\n",
    "\n",
    "        # Iterate through the dataframe to detect when a validation_height exists\n",
    "        for i in range(len(df)):\n",
    "            if not pd.isna(df.loc[i, 'validation_height']):\n",
    "                # We found the end of a sequence, so mark the previous sequence images\n",
    "                sequence_length = i - sequence_start\n",
    "                df.loc[sequence_start:i, 'sequence_length'] = sequence_length + 1  # Using count (1-based index)\n",
    "                sequence_start = i + 1  # Move the start to the next sequence\n",
    "\n",
    "        # Ensure all sequence_length values are integers (if any were missed)\n",
    "        df['sequence_length'] = df['sequence_length'].astype(int)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _print_columns_with_nan(self, df):\n",
    "        \"\"\"\n",
    "        Prints the names of columns in the DataFrame that contain NaN values.\n",
    "        \"\"\"\n",
    "        columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "        if columns_with_nan:\n",
    "            print(\"Columns with NaN values:\")\n",
    "            for col in columns_with_nan:\n",
    "                print(col)\n",
    "        else:\n",
    "            print(\"No columns with NaN values.\")\n",
    "\n",
    "    def _interpolate_missing_values(self, df, exclude_columns=['validation_height', 'timestamp', 'image_path']):\n",
    "        \"\"\"\n",
    "        Interpolates missing values in the DataFrame for all columns except specified ones.\n",
    "        \"\"\"\n",
    "        # Create a copy to avoid modifying the original DataFrame\n",
    "        df = df.copy()\n",
    "\n",
    "        # Store excluded columns\n",
    "        excluded_data = {col: df[col].copy() for col in exclude_columns if col in df.columns}\n",
    "\n",
    "        # Convert all object-type columns in df to numeric where possible\n",
    "        df = df.infer_objects()\n",
    "\n",
    "        # Get columns for interpolation (excluding specified columns)\n",
    "        columns_to_interpolate = [col for col in df.columns if col not in exclude_columns]\n",
    "\n",
    "        # Convert columns to numeric where possible\n",
    "        for col in columns_to_interpolate:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "        # Perform interpolation only on numeric columns\n",
    "        numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        if not numeric_columns.empty:\n",
    "            df[numeric_columns] = df[numeric_columns].interpolate(\n",
    "                method='linear',\n",
    "                axis=0,\n",
    "                limit_direction='both'\n",
    "            )\n",
    "\n",
    "        # Restore excluded columns\n",
    "        for col, data in excluded_data.items():\n",
    "            df[col] = data\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93_LC1v5eLZs"
   },
   "source": [
    "##### Insantiating the data class, loading the data and saving the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82EFqpVEeJC3"
   },
   "outputs": [],
   "source": [
    "# train_dates = [\"60fps_v1/20170418\"]\n",
    "\n",
    "# # Change the cache_cloud_dataset variable at the start to make this either\n",
    "# # generate the CloudDataset (takes some time) or use a cached version on Google Drive.\n",
    "\n",
    "# full_dataset = CloudDataset(train_dates, transform=None)\n",
    "# # Extract the full dataframe from CloudDataset\n",
    "# full_dataframe = full_dataset.data_df\n",
    "# # Ensure folder exists\n",
    "# os.makedirs('yash_datasets', exist_ok=True)\n",
    "# # Save the dataframe directly to Google Drive\n",
    "# full_dataframe.to_csv('yash_datasets/train_dataset.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzU9YKN0ePLm"
   },
   "outputs": [],
   "source": [
    "full_dataframe = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuT1TY6MeR4m"
   },
   "outputs": [],
   "source": [
    "inputs = full_dataframe.drop_duplicates('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1733432400728,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "kr5Q78-1eV1l",
    "outputId": "9ca81d65-3d18-4285-9860-3c44a5f94b26"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "inputs"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-9d489fc3-4985-4a7a-a2a4-87e7452324d3\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>image_path</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>GPS_MSL_Alt</th>\n",
       "      <th>WGS_84_Alt</th>\n",
       "      <th>Press_Alt</th>\n",
       "      <th>Grnd_Spd</th>\n",
       "      <th>True_Airspeed</th>\n",
       "      <th>Mach_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Wind_Speed</th>\n",
       "      <th>Wind_Dir</th>\n",
       "      <th>Solar_Zenith</th>\n",
       "      <th>Sun_Elev_AC</th>\n",
       "      <th>Sun_Az_Grd</th>\n",
       "      <th>Sun_Az_AC</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>validation_height</th>\n",
       "      <th>sequence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2017-04-18 17:57:09</td>\n",
       "      <td>60fps_v1/20170418/170418_175706_183328_frames/...</td>\n",
       "      <td>34.610995</td>\n",
       "      <td>-86.583988</td>\n",
       "      <td>19969.6</td>\n",
       "      <td>19969.8</td>\n",
       "      <td>65045.0</td>\n",
       "      <td>202.8</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.692</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>236.4</td>\n",
       "      <td>23.7</td>\n",
       "      <td>67.3</td>\n",
       "      <td>-173.6</td>\n",
       "      <td>-172.5</td>\n",
       "      <td>17.95</td>\n",
       "      <td>108</td>\n",
       "      <td>13161.0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2017-04-18 17:57:14</td>\n",
       "      <td>60fps_v1/20170418/170418_175706_183328_frames/...</td>\n",
       "      <td>34.620100</td>\n",
       "      <td>-86.583985</td>\n",
       "      <td>19968.1</td>\n",
       "      <td>19968.3</td>\n",
       "      <td>65032.5</td>\n",
       "      <td>202.8</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.692</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>236.3</td>\n",
       "      <td>23.7</td>\n",
       "      <td>67.4</td>\n",
       "      <td>-173.6</td>\n",
       "      <td>-172.4</td>\n",
       "      <td>17.95</td>\n",
       "      <td>108</td>\n",
       "      <td>13131.0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>2017-04-18 17:57:19</td>\n",
       "      <td>60fps_v1/20170418/170418_175706_183328_frames/...</td>\n",
       "      <td>34.629211</td>\n",
       "      <td>-86.583980</td>\n",
       "      <td>19967.6</td>\n",
       "      <td>19967.6</td>\n",
       "      <td>65032.5</td>\n",
       "      <td>202.8</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.692</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>237.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>67.4</td>\n",
       "      <td>-173.5</td>\n",
       "      <td>-172.5</td>\n",
       "      <td>17.95</td>\n",
       "      <td>108</td>\n",
       "      <td>13161.0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>2017-04-18 17:57:24</td>\n",
       "      <td>60fps_v1/20170418/170418_175706_183328_frames/...</td>\n",
       "      <td>34.638317</td>\n",
       "      <td>-86.583978</td>\n",
       "      <td>19967.1</td>\n",
       "      <td>19967.2</td>\n",
       "      <td>65035.0</td>\n",
       "      <td>202.8</td>\n",
       "      <td>200.2</td>\n",
       "      <td>0.691</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>231.4</td>\n",
       "      <td>23.7</td>\n",
       "      <td>67.4</td>\n",
       "      <td>-173.5</td>\n",
       "      <td>-172.5</td>\n",
       "      <td>17.95</td>\n",
       "      <td>108</td>\n",
       "      <td>13191.0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>2017-04-18 17:57:29</td>\n",
       "      <td>60fps_v1/20170418/170418_175706_183328_frames/...</td>\n",
       "      <td>34.647425</td>\n",
       "      <td>-86.583978</td>\n",
       "      <td>19966.6</td>\n",
       "      <td>19966.6</td>\n",
       "      <td>65027.5</td>\n",
       "      <td>202.8</td>\n",
       "      <td>200.8</td>\n",
       "      <td>0.692</td>\n",
       "      <td>...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>231.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>67.4</td>\n",
       "      <td>-173.4</td>\n",
       "      <td>-172.5</td>\n",
       "      <td>17.95</td>\n",
       "      <td>108</td>\n",
       "      <td>13161.0</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d489fc3-4985-4a7a-a2a4-87e7452324d3')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-9d489fc3-4985-4a7a-a2a4-87e7452324d3 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-9d489fc3-4985-4a7a-a2a4-87e7452324d3');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-d546e2c3-7423-4ed7-8981-2398e85a4265\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d546e2c3-7423-4ed7-8981-2398e85a4265')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-d546e2c3-7423-4ed7-8981-2398e85a4265 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                timestamp                                         image_path  \\\n",
       "180   2017-04-18 17:57:09  60fps_v1/20170418/170418_175706_183328_frames/...   \n",
       "480   2017-04-18 17:57:14  60fps_v1/20170418/170418_175706_183328_frames/...   \n",
       "780   2017-04-18 17:57:19  60fps_v1/20170418/170418_175706_183328_frames/...   \n",
       "1080  2017-04-18 17:57:24  60fps_v1/20170418/170418_175706_183328_frames/...   \n",
       "1380  2017-04-18 17:57:29  60fps_v1/20170418/170418_175706_183328_frames/...   \n",
       "\n",
       "            Lat        Lon  GPS_MSL_Alt  WGS_84_Alt  Press_Alt  Grnd_Spd  \\\n",
       "180   34.610995 -86.583988      19969.6     19969.8    65045.0     202.8   \n",
       "480   34.620100 -86.583985      19968.1     19968.3    65032.5     202.8   \n",
       "780   34.629211 -86.583980      19967.6     19967.6    65032.5     202.8   \n",
       "1080  34.638317 -86.583978      19967.1     19967.2    65035.0     202.8   \n",
       "1380  34.647425 -86.583978      19966.6     19966.6    65027.5     202.8   \n",
       "\n",
       "      True_Airspeed  Mach_Number  ...  Wind_Speed  Wind_Dir  Solar_Zenith  \\\n",
       "180           201.0        0.692  ...         3.7     236.4          23.7   \n",
       "480           201.0        0.692  ...         3.5     236.3          23.7   \n",
       "780           201.0        0.692  ...         3.6     237.2          23.7   \n",
       "1080          200.2        0.691  ...         4.0     231.4          23.7   \n",
       "1380          200.8        0.692  ...         3.9     231.8          23.7   \n",
       "\n",
       "      Sun_Elev_AC  Sun_Az_Grd  Sun_Az_AC  hour_of_day  day_of_year  \\\n",
       "180          67.3      -173.6     -172.5        17.95          108   \n",
       "480          67.4      -173.6     -172.4        17.95          108   \n",
       "780          67.4      -173.5     -172.5        17.95          108   \n",
       "1080         67.4      -173.5     -172.5        17.95          108   \n",
       "1380         67.4      -173.4     -172.5        17.95          108   \n",
       "\n",
       "      validation_height  sequence_length  \n",
       "180             13161.0              181  \n",
       "480             13131.0              241  \n",
       "780             13161.0              241  \n",
       "1080            13191.0              241  \n",
       "1380            13161.0              241  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dropna(subset=['validation_height'], inplace=True)\n",
    "inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8eMJHbBNef2A"
   },
   "source": [
    "#### Helper functions for image loading, fisheye correction and cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jS7GG19eYnX"
   },
   "outputs": [],
   "source": [
    "def load_image_from_blob_cv(blob_img, container_client):\n",
    "    \"\"\"\n",
    "    Loads the image from Azure Blob Storage using OpenCV and returns it as a numpy array.\n",
    "    Args:\n",
    "        blob_img (str): name of the blob image in the container\n",
    "        container_client (azure.storage.blob.BlobContainerClient): container client\n",
    "    Returns:\n",
    "        (numpy.ndarray): loaded image with original channels retained\n",
    "    \"\"\"\n",
    "    blob_client = container_client.get_blob_client(blob_img)\n",
    "    streamdownloader = blob_client.download_blob()\n",
    "    blob_data = streamdownloader.readall()\n",
    "    image_array = np.asarray(bytearray(blob_data), dtype=np.uint8)\n",
    "    # img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    img_bgr = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    return img_rgb\n",
    "\n",
    "def undistort_fisheye_image(distorted_image):\n",
    "    \"\"\"\n",
    "    Apply correction for fisheye distortion.\n",
    "    Args:\n",
    "        distorted_image (numpy.ndarray): original image that has the fisheye distortion.\n",
    "     Returns:\n",
    "        (numpy.ndarray): undistorted image with fisheye correction.\n",
    "    \"\"\"\n",
    "    # Parameters provided\n",
    "    f = 1.4  # focal length [mm]\n",
    "    mu = 2.8e-3  # pixel pitch [mm]\n",
    "    S = 2  # output (undistorted) image scale factor\n",
    "    # distortion polynomial order:  [2 4 6 8]\n",
    "    # polynomial coefficients:\n",
    "    coeffs = np.array([0.01166363, -0.04819808, 0.07918044, -0.037572])\n",
    "\n",
    "    H = distorted_image.shape[0]  # image height [pixel]\n",
    "    W = distorted_image.shape[1]  # image width [pixel]\n",
    "    cx = (W - 1) / 2  # image center coordinate [pixel]\n",
    "    cy = (H - 1) / 2  # image center coordinate [pixel]\n",
    "\n",
    "    K = np.array([[f / mu, 0, cx], [0, f / mu, cy], [0, 0, 1]])\n",
    "\n",
    "    # compute intrinsic matrix for undistorted image\n",
    "    cpx = (W * S - 1) / 2\n",
    "    cpy = (H * S - 1) / 2\n",
    "    P = np.array([[f / mu, 0, cpx], [0, f / mu, cpy], [0, 0, 1]])\n",
    "\n",
    "    # rectification matrix (identity)\n",
    "    R = np.eye(3)\n",
    "\n",
    "    # produce undistorted image\n",
    "    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K=K, D=coeffs, R=R, P=P, size=[W * S, H * S], m1type=cv2.CV_16SC2)\n",
    "    undistorted_image = cv2.remap(distorted_image, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_TRANSPARENT)\n",
    "    return undistorted_image\n",
    "\n",
    "def crop_and_correct_image_cv2(image, size1=(1500, 1500), offset=(85, 180), size2=(800, 800)):\n",
    "    \"\"\"\n",
    "    Crops the undistorted image in two stages and ensures the original center (960, 540)\n",
    "    aligns with the center of the final cropped image (400, 400).\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image to crop.\n",
    "        size1 (tuple): Size of the first crop (width, height).\n",
    "        offset (tuple): Offset for the first crop.\n",
    "        size2 (tuple): Size of the final crop (width, height).\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Cropped image.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "\n",
    "    # Step 1: First crop with offset\n",
    "    center_h, center_w = h // 2, w // 2  # Center of the undistorted image\n",
    "    offset_h, offset_w = offset\n",
    "\n",
    "    # Adjust the starting coordinates for the first crop\n",
    "    start_h1 = max(center_h - size1[1] // 2 + offset_h, 0)\n",
    "    start_w1 = max(center_w - size1[0] // 2 + offset_w, 0)\n",
    "    cropped_image = image[start_h1:start_h1 + size1[1], start_w1:start_w1 + size1[0]]\n",
    "\n",
    "    # Step 2: Adjust second crop to ensure the original center aligns with the center of the crop-corrected image\n",
    "    crop_h, crop_w = size2\n",
    "    center_h_crop = center_h - start_h1  # Adjusted center in the cropped image\n",
    "    center_w_crop = center_w - start_w1\n",
    "\n",
    "    # Calculate start coordinates to place the center at 400, 400\n",
    "    start_h2 = max(center_h_crop - crop_h // 2, 0)\n",
    "    start_w2 = max(center_w_crop - crop_w // 2, 0)\n",
    "\n",
    "    final_image = cropped_image[start_h2:start_h2 + crop_h, start_w2:start_w2 + crop_w]\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDO99rBWe8Fb"
   },
   "source": [
    "#### Optical flow related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkTjarCxell3"
   },
   "outputs": [],
   "source": [
    "def sampling_framerate(desired_sampling_rate_fps=20, actual_framerate_fps=60):\n",
    "    \"\"\"\n",
    "    For chandrakant's method, minimum desired sampling rate is 2 fps. His original successful run tries 20fps\n",
    "    :param desired_sampling_rate_fps:\n",
    "    :param actual_framerate_fps:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    fincrement = int(actual_framerate_fps/desired_sampling_rate_fps)\n",
    "    return fincrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEZYQffof7jc"
   },
   "outputs": [],
   "source": [
    "def getData(x,y,z):\n",
    "  temp = z[x,y]\n",
    "  return temp\n",
    "\n",
    "f=np.vectorize(getData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "etWc-SE-iBRG"
   },
   "outputs": [],
   "source": [
    "def get_undistorted_endpoints_1(mu, S, H, W, x, y):\n",
    "    cx = (W-1)/2        # image center coordinate [pixel]\n",
    "    cy = (H-1)/2        # image center coordinate [pixel]\n",
    "\n",
    "    K = np.array([[f/mu,0,cx],[0,f/mu,cy],[0,0,1]])\n",
    "\n",
    "    # compute intrinsic matrix for ouput image\n",
    "    cpx = (W*S-1)/2\n",
    "    cpy = (H*S-1)/2\n",
    "    P = np.array([[f/mu,0,cpx],[0,f/mu,cpy],[0,0,1]])\n",
    "\n",
    "    D = np.array([0.01166363, -0.04819808, 0.07918044, -0.037572])\n",
    "\n",
    "    R = np.eye(3)\n",
    "\n",
    "    coord_homog = np.array([x, y, 1.0], dtype=np.float32).reshape(-1, 1)\n",
    "    undistorted_coord = cv2.fisheye.undistortPoints(\n",
    "        coord_homog.T[:, :2].reshape(1, -1, 2),\n",
    "        K=K, D=D, R=R, P=P\n",
    "    )[0][0]\n",
    "    x_1, y_1 = undistorted_coord\n",
    "\n",
    "    return x_1, y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2TvkpkQDiKUE"
   },
   "outputs": [],
   "source": [
    "def get_speed(first_pixel, last_pixel, first_frame, last_frame):\n",
    "    mu = 7.7/1082\n",
    "    travelled_pixels = last_pixel - first_pixel\n",
    "    travel_time = (last_frame - first_frame)/60\n",
    "\n",
    "    travelled_distance = travelled_pixels * mu\n",
    "    #print(travelled_pixels, travelled_distance, travel_time)\n",
    "\n",
    "    #if travel_time != 0:\n",
    "    u = travelled_distance/travel_time\n",
    "    #else:\n",
    "        #u = 0\n",
    "\n",
    "    return u\n",
    "\n",
    "s = np.vectorize(get_speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZhjQVLgiYW4"
   },
   "outputs": [],
   "source": [
    "def Create_Output(X_Coord,Y_Coord,height):\n",
    "    output = [X_Coord, Y_Coord, height]\n",
    "\n",
    "    return output\n",
    "\n",
    "final = np.vectorize(Create_Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6cdOfJJimW4"
   },
   "outputs": [],
   "source": [
    "def get_center_region(img1_1, r_h, r_w):\n",
    "  h, w = img1_1.shape\n",
    "\n",
    "  center_x, center_y = w // 2, h // 2\n",
    "  half_width, half_height =  r_w // 2, r_h // 2\n",
    "  center_region = (slice(center_y - half_height, center_y + half_height), slice(center_x - half_width, center_x + half_width))\n",
    "\n",
    "  return center_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bYLBvCksjVJE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh__D4NKlQDx"
   },
   "source": [
    "####Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_GOrkkYlS1g"
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "maxtrack_time = 5\n",
    "#last framenum to check where pixel went\n",
    "end_frame_loop = maxtrack_time * 60\n",
    "ACTUAL_FRAMERATE = 60 #FPS\n",
    "H = 600\n",
    "W = 600\n",
    "\n",
    "frame_pixels = 1082\n",
    "mu = 8/1082\n",
    "f = 1.4\n",
    "mu_1 = 2.8e-3\n",
    "S = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25_tUmnR_dOt"
   },
   "outputs": [],
   "source": [
    "inputs = pd.read_excel(\"/content/drive/MyDrive/Input_1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kr6pyg7cX4J"
   },
   "outputs": [],
   "source": [
    "#!unzip '/content/drive/MyDrive/frame331.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1733432401976,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "2dUYB64UdKRd",
    "outputId": "234aae68-6831-46ae-a7ca-686aeb17d82f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(slice(240, 840, None), slice(660, 1260, None))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1_1 = load_image_from_blob_cv(\"170418_175706_183328_All_Frames/frame0.jpg\", container_client)\n",
    "img1 = cv2.cvtColor(img1_1, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "center_region = get_center_region(img1, 600, 600)\n",
    "center_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1733432401976,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "37HBiWmCdiIA",
    "outputId": "23cebea7-d100-4f13-dd5c-8cf4c7a82261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fincrement = sampling_framerate(desired_sampling_rate_fps=20, actual_framerate_fps=ACTUAL_FRAMERATE)\n",
    "fincrement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1c2cF8GJZ3F"
   },
   "outputs": [],
   "source": [
    "# Precalculate fisheye corrected co-ordinates\n",
    "x_corr = np.zeros([H, W])\n",
    "y_corr = np.zeros([H, W])\n",
    "\n",
    "for i in range(H):\n",
    "    for j in range(W):\n",
    "        k_1, k = get_undistorted_endpoints_1(mu_1, S, H, W, j, i)\n",
    "\n",
    "        x_corr[i,j] = k\n",
    "        y_corr[i,j] = k_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-KIivPYUGU9g"
   },
   "outputs": [],
   "source": [
    "optical_flow_cuda = cv2.cuda.OpticalFlowDual_TVL1_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 214820,
     "status": "ok",
     "timestamp": 1733433538902,
     "user": {
      "displayName": "Chandrakant Shendarkar",
      "userId": "10054899019773251246"
     },
     "user_tz": -330
    },
    "id": "K3e05B1dGW4z",
    "outputId": "3d2bb7ca-4ae4-4966-d4b6-9654e94beac5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 431/431 [03:34<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken in s: 214.3976788520813 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for ind in tqdm(inputs.index):\n",
    "    st = time.time()\n",
    "\n",
    "    if ind == 2:\n",
    "      # Get all motion comparisons\n",
    "      first_frame = inputs['First Frame'][ind]\n",
    "      results = []\n",
    "      cnt = 0\n",
    "\n",
    "      for i in range(first_frame, first_frame+end_frame_loop, fincrement):\n",
    "        #print(datetime.now(), cnt)\n",
    "        img1_1 = load_image_from_blob_cv(\"170418_175706_183328_All_Frames/frame%d.jpg\" % i, container_client)\n",
    "        #img1_1 = cv2.imread('frame%d.jpg' % i, cv2.IMREAD_GRAYSCALE)\n",
    "        #img1_1 = load_image_from_blob_cv(full_dataframe['image_path'][first_frame], container_client)\n",
    "        img1_1 = cv2.cvtColor(img1_1, cv2.COLOR_RGB2GRAY)\n",
    "        img1_1[img1_1<75]=0\n",
    "        img1 = img1_1[center_region]\n",
    "\n",
    "        for j in range(i+fincrement, i+31,fincrement):\n",
    "          img2_1 = load_image_from_blob_cv(\"170418_175706_183328_All_Frames/frame%d.jpg\" % j, container_client)\n",
    "          #img2_1 = cv2.imread('frame%d.jpg' % j, cv2.IMREAD_GRAYSCALE)\n",
    "          #img2_1 = load_image_from_blob_cv(full_dataframe['image_path'][j], container_client)\n",
    "          img2_1 = cv2.cvtColor(img2_1, cv2.COLOR_RGB2GRAY)\n",
    "          img2_1[img2_1<75]=0\n",
    "          img2 = img2_1[center_region]\n",
    "\n",
    "          cuMat1 = cv2.cuda_GpuMat()\n",
    "          cuMat2 = cv2.cuda_GpuMat()\n",
    "          cuMat1.upload(img1)\n",
    "          cuMat2.upload(img2)\n",
    "\n",
    "          cu_flow = optical_flow_cuda.calc(cuMat1, cuMat2, None)\n",
    "          optical_flow_data = cu_flow.download()\n",
    "\n",
    "          results.append([i, j, optical_flow_data])\n",
    "          cnt += 1\n",
    "\n",
    "      # Calculate first position change for all frames\n",
    "      one_cycle = int(30/fincrement)\n",
    "      total_comparisons = int(end_frame_loop/fincrement * one_cycle)\n",
    "\n",
    "      movement_all = []\n",
    "      for frame in range(0, total_comparisons, one_cycle):\n",
    "          posn_change = np.zeros([H,W])\n",
    "          v = np.zeros([H, W])\n",
    "          u = np.zeros([H, W])\n",
    "          for i in range(one_cycle):\n",
    "              #print(results[frame+i][0], results[frame+i][1])\n",
    "\n",
    "              v_1 = np.copy(results[frame+i][2][:,:,0])\n",
    "              u_1 = np.copy(results[frame+i][2][:,:,1])\n",
    "\n",
    "              temp1 = (abs(u_1) >=1).astype(int)\n",
    "              temp2 = (abs(v_1) >=1).astype(int)\n",
    "              temp3 = temp1 + temp2\n",
    "\n",
    "              temp4 = (temp3 >=1).astype(int)\n",
    "              temp5 = (posn_change < 100).astype(int)\n",
    "\n",
    "              temp6 = np.multiply(temp4, temp5)\n",
    "\n",
    "              posn_change = posn_change + temp6*(i+1)*100\n",
    "              u = u + np.multiply(temp6, u_1)\n",
    "              v = v + np.multiply(temp6, v_1)\n",
    "\n",
    "          movement_all.append([results[frame][0], posn_change, u, v])\n",
    "\n",
    "          #with open(str(results[frame][0]) + \".pkl\", \"wb\") as fp:   #Pickling\n",
    "              #pickle.dump(movement, fp)\n",
    "\n",
    "          #fp.close()\n",
    "\n",
    "      #  Calculate path of each pixel\n",
    "      #with open(str(first_frame) + \".pkl\", 'rb') as fp:\n",
    "        #movement = pickle.load(fp) # deserialize using load()\n",
    "\n",
    "      #os.remove(str(first_frame) + \".pkl\")\n",
    "      movement = movement_all[0]\n",
    "      posn = movement[1]\n",
    "      u = movement[2]\n",
    "      v = movement[3]\n",
    "\n",
    "      x = np.arange(H)\n",
    "      y = np.arange(W)\n",
    "\n",
    "      x_1, y_1 = np.meshgrid(y,x)\n",
    "\n",
    "      u_1 = getData(y_1, x_1, u)\n",
    "      v_1 = getData(y_1, x_1, v)\n",
    "\n",
    "      x_1 = x_1 + np.round(v_1)\n",
    "      y_1 = y_1 + np.round(u_1)\n",
    "\n",
    "      x_1[x_1>W-1] = 0\n",
    "      y_1[y_1>H-1] = 0\n",
    "\n",
    "      for i in range(1, int(total_comparisons/one_cycle)):\n",
    "        #j= i*fincrement + first_frame\n",
    "        #with open(str(j) + \".pkl\", 'rb') as fp:\n",
    "            #movement = pickle.load(fp)\n",
    "\n",
    "        #os.remove(str(j) + \".pkl\")\n",
    "\n",
    "        movement = movement_all[i]\n",
    "        u = movement[2]\n",
    "        v = movement[3]\n",
    "        u_1 = getData(y_1.astype('int32'), x_1.astype('int32'), u)\n",
    "        v_1 = getData(y_1.astype('int32'), x_1.astype('int32'), v)\n",
    "        posn_1 = getData(y_1.astype('int32'), x_1.astype('int32'), movement[1])\n",
    "\n",
    "        temp1 = (posn ==i*100).astype(int)\n",
    "\n",
    "        posn_1 = np.multiply(posn_1, temp1)\n",
    "        u_1 = np.multiply(u_1, temp1)\n",
    "        v_1 = np.multiply(v_1, temp1)\n",
    "\n",
    "        posn = posn + posn_1\n",
    "        x_1 = x_1 + np.round(v_1)\n",
    "        y_1 = y_1 + np.round(u_1)\n",
    "        x_1[x_1>W-1] = 0\n",
    "        y_1[y_1>H-1] = 0\n",
    "\n",
    "      # Get last pixels and frame\n",
    "      x_last = getData(y_1.astype('int32'), x_1.astype('int32'), x_corr)\n",
    "      y_last = getData(y_1.astype('int32'), x_1.astype('int32'), y_corr)\n",
    "\n",
    "      frame_last = posn*fincrement/100\n",
    "\n",
    "      # Calculate speed of each point\n",
    "      u = get_speed(x_corr, x_last, 0, frame_last)\n",
    "      u[np.isnan(u)] = 0\n",
    "\n",
    "      # Calculate height of each pixel\n",
    "      height = (inputs['GPS_MSL_Alt'][ind] - f*inputs['Grnd_Spd'][ind]/u)/math.cos(math.pi*inputs['Pitch'][ind]/180)\n",
    "      height[height == -inf] = 0\n",
    "\n",
    "      # Create output\n",
    "      x = np.arange(H)\n",
    "      y = np.arange(W)\n",
    "\n",
    "      x_coord, y_coord = np.meshgrid(y,x)\n",
    "\n",
    "      #Output = np.column_stack((y_coord[center_region].ravel(),x_coord[center_region].ravel(), height[center_region].ravel()))\n",
    "      Output = np.column_stack((y_coord.ravel(),x_coord.ravel(), height.ravel()))\n",
    "\n",
    "      np.savetxt(\"/content/drive/MyDrive/Outputs/Output_%d.csv\" % ind, Output, delimiter=\",\", fmt=\"%.2f\",\n",
    "           header=\"X,Y,Height\", comments=\"\")\n",
    "\n",
    "      print(f\"Time Taken in s: {time.time() - st}\", ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ik93y3uLUA5i"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOvTQh35sVerVgmVsMsGE1u",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
