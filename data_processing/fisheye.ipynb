{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install azure-storage-blob azure-identity --quiet\n","!pip install tensorflow-io --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SRymVR6jQ3l","executionInfo":{"status":"ok","timestamp":1731737311256,"user_tz":-330,"elapsed":41018,"user":{"displayName":"Yash Nahar","userId":"15294922963682605910"}},"outputId":"d29ded65-62ff-4130-cf45-ac9da570c333"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.6/187.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/harvard.dce.nasa.cloud2cloud"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vGMXqWy7jTjL","executionInfo":{"status":"ok","timestamp":1731737332931,"user_tz":-330,"elapsed":21680,"user":{"displayName":"Yash Nahar","userId":"15294922963682605910"}},"outputId":"e5e0c2bb-7eb6-45b3-bd44-159c0cfcb880"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/harvard.dce.nasa.cloud2cloud\n"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","account_name = userdata.get('storage_account_name')\n","account_key = userdata.get('storage_account_key')\n","container_name = userdata.get('blob_container_name')\n","\n","os.environ['TF_AZURE_STORAGE_KEY'] = account_key"],"metadata":{"id":"8f36Nj4MjVsK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from azure.storage.blob import BlobServiceClient\n","import pandas as pd\n","\n","# more info https://learn.microsoft.com/en-us/python/api/overview/azure/storage-blob-readme?view=azure-python\n","connection_string = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n","\n","# setup to load file from blob\n","blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n","container_client = blob_service_client.get_container_client(container_name)"],"metadata":{"id":"rLSWv9W3jXyR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd capstone_2024/cloud_features_tracking/\n","import cloud2cloud_ConvNext as CN"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T8NupeTYjahR","executionInfo":{"status":"ok","timestamp":1731737368515,"user_tz":-330,"elapsed":27243,"user":{"displayName":"Yash Nahar","userId":"15294922963682605910"}},"outputId":"c0fae4c9-156a-4ac4-d3e6-85875bcd89fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/harvard.dce.nasa.cloud2cloud/capstone_2024/cloud_features_tracking\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqHo_BV6iwf8"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from transformers import AutoImageProcessor, ConvNextModel\n","from PIL import Image\n","import tensorflow as tf\n","import tensorflow_io as tfio\n","from azure.storage.blob import BlobServiceClient\n","\n","\n","def load_image_from_blob_cv(blob_img, container_client):\n","    \"\"\"\n","    Loads the image from Azure Blob Storage using OpenCV and returns it as a numpy array.\n","    Args:\n","        blob_img (str): name of the blob image in the container\n","        container_client (azure.storage.blob.BlobContainerClient): container client\n","    Returns:\n","        (numpy.ndarray): loaded image with original channels retained\n","    \"\"\"\n","    blob_client = container_client.get_blob_client(blob_img)\n","    streamdownloader = blob_client.download_blob()\n","    blob_data = streamdownloader.readall()\n","    image_array = np.asarray(bytearray(blob_data), dtype=np.uint8)\n","    # img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n","    img_bgr = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n","    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n","    return img_rgb\n","\n","\n","def undistort_fisheye_image(distorted_image):\n","    \"\"\"\n","    Apply correction for fisheye distortion.\n","    Args:\n","        distorted_image (numpy.ndarray): original image that has the fisheye distortion.\n","     Returns:\n","        (numpy.ndarray): undistorted image with fisheye correction.\n","    \"\"\"\n","    # Parameters provided\n","    f = 1.4  # focal length [mm]\n","    mu = 2.8e-3  # pixel pitch [mm]\n","    S = 2  # output (undistorted) image scale factor\n","    # distortion polynomial order:  [2 4 6 8]\n","    # polynomial coefficients:\n","    coeffs = np.array([0.01166363, -0.04819808, 0.07918044, -0.037572])\n","\n","    H = distorted_image.shape[0]  # image height [pixel]\n","    W = distorted_image.shape[1]  # image width [pixel]\n","    cx = (W - 1) / 2  # image center coordinate [pixel]\n","    cy = (H - 1) / 2  # image center coordinate [pixel]\n","\n","    K = np.array([[f / mu, 0, cx], [0, f / mu, cy], [0, 0, 1]])\n","\n","    # compute intrinsic matrix for undistorted image\n","    cpx = (W * S - 1) / 2\n","    cpy = (H * S - 1) / 2\n","    P = np.array([[f / mu, 0, cpx], [0, f / mu, cpy], [0, 0, 1]])\n","\n","    # rectification matrix (identity)\n","    R = np.eye(3)\n","\n","    # produce undistorted image\n","    map1, map2 = cv2.fisheye.initUndistortRectifyMap(K=K, D=coeffs, R=R, P=P, size=[W * S, H * S], m1type=cv2.CV_16SC2)\n","    undistorted_image = cv2.remap(distorted_image, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_TRANSPARENT)\n","    return undistorted_image\n","\n","\n","def crop_and_correct_image_cv(image, size1=(1500, 1500), offset=(85, 180), size2=(1000, 1000)):\n","    h, w = image.shape[:2]\n","\n","    # Cropping it to 1500X1500 and accounting for offset.\n","    center_h, center_w = h // 2, w // 2\n","    offset_h, offset_w = offset\n","    start_h = min(max(center_h - size1[0] // 2 + offset_h, 0), h - size1[0])\n","    start_w = min(max(center_w - size1[1] // 2 + offset_w, 0), w - size1[1])\n","    cropped_image = image[start_h:start_h + size1[0], start_w:start_w + size1[1]]\n","    h, w = cropped_image.shape[:2]\n","\n","    # further crop the image to 1000X1000\n","    center_h, center_w = h // 2, w // 2\n","    start_h = max(center_h - size2[0] // 2, 0)\n","    start_w = max(center_w - size2[1] // 2, 0)\n","\n","    return cropped_image[start_h:start_h + size2[0], start_w:start_w + size2[1]]\n","\n","def crop_and_correct_image_cv2(image, size1=(1500, 1500), offset=(85, 180), size2=(800, 800)):\n","    \"\"\"\n","    Crops the undistorted image in two stages and ensures the original center (960, 540)\n","    aligns with the center of the final cropped image (400, 400).\n","\n","    Args:\n","        image (numpy.ndarray): Input image to crop.\n","        size1 (tuple): Size of the first crop (width, height).\n","        offset (tuple): Offset for the first crop.\n","        size2 (tuple): Size of the final crop (width, height).\n","\n","    Returns:\n","        numpy.ndarray: Cropped image.\n","    \"\"\"\n","    h, w = image.shape[:2]\n","\n","    # Step 1: First crop with offset\n","    center_h, center_w = h // 2, w // 2  # Center of the undistorted image\n","    offset_h, offset_w = offset\n","\n","    # Adjust the starting coordinates for the first crop\n","    start_h1 = max(center_h - size1[1] // 2 + offset_h, 0)\n","    start_w1 = max(center_w - size1[0] // 2 + offset_w, 0)\n","    cropped_image = image[start_h1:start_h1 + size1[1], start_w1:start_w1 + size1[0]]\n","\n","    # Step 2: Adjust second crop to ensure the original center aligns with the center of the crop-corrected image\n","    crop_h, crop_w = size2\n","    center_h_crop = center_h - start_h1  # Adjusted center in the cropped image\n","    center_w_crop = center_w - start_w1\n","\n","    # Calculate start coordinates to place the center at 400, 400\n","    start_h2 = max(center_h_crop - crop_h // 2, 0)\n","    start_w2 = max(center_w_crop - crop_w // 2, 0)\n","\n","    final_image = cropped_image[start_h2:start_h2 + crop_h, start_w2:start_w2 + crop_w]\n","\n","    return final_image\n","\n","\n","\n","def save_cropped_image(container_client, cropped_img, src_blob_name, dest):\n","    \"\"\"\n","    Saves the cropped image to Azure Blob Storage with a modified folder name using OpenCV.\n","\n","    Args:\n","        container_client (azure.storage.blob.ContainerClient): Azure blob storage container client\n","        cropped_img (numpy.ndarray): Cropped image as a numpy array.\n","        src_blob_name (str): Source blob name.\n","        dest (str): The folder where cropped images will be saved.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    cropped_img_rgb = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n","    is_success, buffer = cv2.imencode('.jpg', cropped_img_rgb)\n","    if not is_success:\n","        raise ValueError(\"Failed to encode image with OpenCV.\")\n","\n","    img_byte_array = BytesIO(buffer)\n","\n","    base_name = os.path.basename(src_blob_name)\n","    cropped_blob_name = os.path.join(dest, base_name)\n","\n","    blob_client = container_client.get_blob_client(cropped_blob_name)\n","    blob_client.upload_blob(img_byte_array.getvalue(), overwrite=True)\n","\n","\n","def crop_and_correct_images_in_blob(container_client, src, dest):\n","    \"\"\"\n","    Reads images from src dir in an azure blob, applies crop_to_square,\n","    and uploads cropped images to dest dir in the same blob.\n","\n","    Args:\n","        container_client (azure.storage.blob.ContainerClient): azure blob storage container client\n","        src (str): path to the dir containing src images.\n","        dest (str): path to the dir with cropped images.\n","\n","    Returns:\n","        (str): path to the cropped images directory.\n","    \"\"\"\n","    blobs = container_client.list_blobs(name_starts_with=src)\n","    existing_blobs = {blob.name for blob in container_client.list_blobs(name_starts_with=dest)}\n","    for blob in blobs:\n","        dir = os.path.dirname(blob.name)\n","        if dir.endswith('_frames') and blob.name.endswith('.jpg'):\n","            base_name = os.path.basename(blob.name)\n","            new_filename = base_name.replace('.jpg', '_crop_corrected.jpg')\n","            cropped_blob_name = os.path.join(dest, new_filename)\n","            if cropped_blob_name in existing_blobs:\n","                continue\n","            img_stream = load_image_from_blob_cv(blob.name, container_client)\n","            fisheye_corrected_img = undistort_fisheye_image(img_stream)\n","            cropped_img = crop_and_correct_image_cv(fisheye_corrected_img)\n","\n","            save_cropped_image(container_client, cropped_img, blob.name, dest)\n","    return dest"]},{"cell_type":"code","source":["def map_coordinates(coord, original_size=(1920, 1080), fisheye_params=None, crop_size1=(1500, 1500), crop_offset=(85, 180), crop_size2=(1000, 1000)):\n","    \"\"\"\n","    Maps a coordinate from the original image to the undistorted image and the crop-corrected image.\n","\n","    Args:\n","        coord (tuple): (x, y) coordinate in the original image.\n","        original_size (tuple): Size of the original image (width, height).\n","        fisheye_params (dict): Parameters for the fisheye undistortion.\n","        crop_size1 (tuple): Size of the first crop (width, height).\n","        crop_offset (tuple): Offset applied to the first crop.\n","        crop_size2 (tuple): Size of the second crop (width, height).\n","\n","    Returns:\n","        dict: A dictionary with mappings to undistorted and crop-corrected coordinates.\n","    \"\"\"\n","    x, y = coord\n","\n","    # Map from original to undistorted image\n","    if fisheye_params:\n","        K = fisheye_params[\"K\"]\n","        D = fisheye_params[\"D\"]\n","        R = fisheye_params.get(\"R\", np.eye(3))\n","        P = fisheye_params[\"P\"]\n","\n","        # Normalize coordinates to camera space\n","        coord_homog = np.array([x, y, 1.0], dtype=np.float32).reshape(-1, 1)\n","        undistorted_coord = cv2.fisheye.undistortPoints(\n","            coord_homog.T[:, :2].reshape(1, -1, 2),\n","            K=K, D=D, R=R, P=P\n","        )[0][0]\n","        x_undist, y_undist = undistorted_coord\n","    else:\n","        x_undist, y_undist = x, y\n","\n","    # Map from undistorted to crop-corrected image (first crop)\n","    undist_h, undist_w = original_size[1] * 2, original_size[0] * 2  # Account for fisheye scaling\n","    center_h, center_w = undist_h // 2, undist_w // 2\n","    offset_h, offset_w = crop_offset\n","\n","    # First crop coordinates\n","    start_h1 = max(center_h - crop_size1[1] // 2 + offset_h, 0)\n","    start_w1 = max(center_w - crop_size1[0] // 2 + offset_w, 0)\n","    x_cropped1 = x_undist - start_w1\n","    y_cropped1 = y_undist - start_h1\n","\n","    # Map from first cropped image to final crop-corrected image\n","    crop1_h, crop1_w = crop_size1\n","    center_h1, center_w1 = crop1_h // 2, crop1_w // 2\n","\n","    # Adjust for alignment to center (500, 500)\n","    start_h2 = center_h1 - crop_size2[1] // 2\n","    start_w2 = center_w1 - crop_size2[0] // 2\n","    x_cropped2 = x_cropped1 - start_w2\n","    y_cropped2 = y_cropped1 - start_h2\n","\n","    # Return both mapped coordinates\n","    return {\n","        \"undistorted\": (x_undist, y_undist),\n","        \"crop_corrected\": (x_cropped2, y_cropped2)\n","    }\n","\n","def map_coordinates2(coord, original_size=(1920, 1080), fisheye_params=None, crop_size1=(1500, 1500), crop_offset=(85, 180), crop_size2=(800, 800)):\n","    \"\"\"\n","    Maps a coordinate from the original image to the undistorted image and the crop-corrected image.\n","\n","    Args:\n","        coord (tuple): (x, y) coordinate in the original image.\n","        original_size (tuple): Size of the original image (width, height).\n","        fisheye_params (dict): Parameters for the fisheye undistortion.\n","        crop_size1 (tuple): Size of the first crop (width, height).\n","        crop_offset (tuple): Offset applied to the first crop.\n","        crop_size2 (tuple): Size of the second crop (width, height).\n","\n","    Returns:\n","        dict: A dictionary with mappings to undistorted and crop-corrected coordinates.\n","    \"\"\"\n","    x, y = coord\n","\n","    # Step 1: Map from original to undistorted image\n","    if fisheye_params:\n","        K = fisheye_params[\"K\"]\n","        D = fisheye_params[\"D\"]\n","        R = fisheye_params.get(\"R\", np.eye(3))\n","        P = fisheye_params[\"P\"]\n","\n","        # Normalize coordinates to camera space\n","        coord_homog = np.array([x, y, 1.0], dtype=np.float32).reshape(-1, 1)\n","        undistorted_coord = cv2.fisheye.undistortPoints(\n","            coord_homog.T[:, :2].reshape(1, -1, 2),\n","            K=K, D=D, R=R, P=P\n","        )[0][0]\n","        x_undist, y_undist = undistorted_coord\n","    else:\n","        x_undist, y_undist = x, y  # No undistortion applied\n","\n","    # Step 2: Map from undistorted to first cropped image\n","    undist_h, undist_w = original_size[1] * 2, original_size[0] * 2  # Account for fisheye scaling\n","    center_h, center_w = undist_h // 2, undist_w // 2\n","    offset_h, offset_w = crop_offset\n","\n","    # First crop starting points\n","    start_h1 = max(center_h - crop_size1[1] // 2 + offset_h, 0)\n","    start_w1 = max(center_w - crop_size1[0] // 2 + offset_w, 0)\n","    x_cropped1 = x_undist - start_w1\n","    y_cropped1 = y_undist - start_h1\n","\n","    # Step 3: Map from first cropped image to final crop-corrected image\n","    center_h_crop = center_h - start_h1  # Adjusted center in the first cropped image\n","    center_w_crop = center_w - start_w1\n","\n","    # Adjust coordinates for final cropping stage\n","    start_h2 = max(center_h_crop - crop_size2[1] // 2, 0)\n","    start_w2 = max(center_w_crop - crop_size2[0] // 2, 0)\n","    x_cropped2 = x_cropped1 - start_w2\n","    y_cropped2 = y_cropped1 - start_h2\n","\n","    # Return the coordinates for both stages\n","    return {\n","        \"undistorted\": (x_undist, y_undist),\n","        \"crop_corrected\": (x_cropped2, y_cropped2)\n","    }\n","\n","def unmap_coordinates2(crop_corrected_coord, original_size=(1920, 1080), fisheye_params=None,\n","                       crop_size1=(1500, 1500), crop_offset=(85, 180), crop_size2=(800, 800)):\n","    \"\"\"\n","    Reverses the mapping from crop-corrected coordinates to the undistorted and original image coordinates.\n","\n","    Args:\n","        crop_corrected_coord (tuple): (x, y) coordinate in the crop-corrected image.\n","        original_size (tuple): Size of the original image (width, height).\n","        fisheye_params (dict): Parameters for the fisheye distortion.\n","        crop_size1 (tuple): Size of the first crop (width, height).\n","        crop_offset (tuple): Offset applied to the first crop.\n","        crop_size2 (tuple): Size of the second crop (width, height).\n","\n","    Returns:\n","        dict: A dictionary with mappings to undistorted and original coordinates.\n","    \"\"\"\n","    x_cropped2, y_cropped2 = crop_corrected_coord\n","\n","    # Step 1: Reconstruct the undistorted coordinates\n","    undist_h, undist_w = original_size[1] * 2, original_size[0] * 2  # Account for fisheye scaling\n","    center_h, center_w = undist_h // 2, undist_w // 2\n","    offset_h, offset_w = crop_offset\n","\n","    # First crop starting points\n","    start_h1 = max(center_h - crop_size1[1] // 2 + offset_h, 0)\n","    start_w1 = max(center_w - crop_size1[0] // 2 + offset_w, 0)\n","\n","    # Adjusted center in the first cropped image\n","    center_h_crop = center_h - start_h1\n","    center_w_crop = center_w - start_w1\n","\n","    # Second crop starting points\n","    start_h2 = max(center_h_crop - crop_size2[1] // 2, 0)\n","    start_w2 = max(center_w_crop - crop_size2[0] // 2, 0)\n","\n","    # Reconstruct undistorted coordinates\n","    x_cropped1 = x_cropped2 + start_w2\n","    y_cropped1 = y_cropped2 + start_h2\n","    x_undist = x_cropped1 + start_w1\n","    y_undist = y_cropped1 + start_h1\n","\n","    # Step 2: Adjust undistorted coordinates to match the original camera matrix\n","    if fisheye_params:\n","        K = fisheye_params[\"K\"]\n","        D = fisheye_params[\"D\"]\n","        P = fisheye_params[\"P\"]\n","\n","        # Compute the offset between the principal points of K and P\n","        cx_offset = P[0, 2] - K[0, 2]\n","        cy_offset = P[1, 2] - K[1, 2]\n","\n","        # Adjust the undistorted coordinates\n","        x_undist_adjusted = x_undist - cx_offset\n","        y_undist_adjusted = y_undist - cy_offset\n","\n","        # Normalize the adjusted undistorted coordinates\n","        x_norm_undist = (x_undist_adjusted - K[0, 2]) / K[0, 0]\n","        y_norm_undist = (y_undist_adjusted - K[1, 2]) / K[1, 1]\n","\n","        # Prepare undistorted normalized coordinates\n","        undistorted_points = np.array([[[x_norm_undist, y_norm_undist]]], dtype=np.float64)\n","\n","        # Apply fisheye distortion to get normalized distorted coordinates\n","        distorted_points = cv2.fisheye.distortPoints(\n","            undistorted_points,\n","            K=np.eye(3),\n","            D=D\n","        )\n","\n","        # Map normalized distorted coordinates back to pixel coordinates using K\n","        x_distorted = distorted_points[0, 0, 0] * K[0, 0] + K[0, 2]\n","        y_distorted = distorted_points[0, 0, 1] * K[1, 1] + K[1, 2]\n","        x, y = x_distorted, y_distorted\n","    else:\n","        x, y = x_undist, y_undist  # No distortion applied\n","\n","    # Return the coordinates for both stages\n","    return {\n","        \"undistorted\": (x_undist, y_undist),\n","        \"original\": (x, y)\n","    }\n"],"metadata":{"id":"zHVx3MEIiyKu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def get_fisheye_params(image_width, image_height, f=1.4, mu=2.8e-3, S=2):\n","    \"\"\"\n","    Compute fisheye parameters (K, D, R, P) based on the given image dimensions and parameters.\n","\n","    Args:\n","        image_width (int): Width of the original image.\n","        image_height (int): Height of the original image.\n","        f (float): Focal length in mm.\n","        mu (float): Pixel pitch in mm/pixel.\n","        S (float): Scaling factor for the undistorted image.\n","\n","    Returns:\n","        dict: Dictionary containing K, D, R, and P matrices.\n","    \"\"\"\n","    # Intrinsic matrix for the original image\n","    cx = (image_width - 1) / 2\n","    cy = (image_height - 1) / 2\n","    K = np.array([\n","        [f / mu, 0, cx],\n","        [0, f / mu, cy],\n","        [0, 0, 1]\n","    ])\n","\n","    # Distortion coefficients\n","    D = np.array([0.01166363, -0.04819808, 0.07918044, -0.037572])\n","\n","    # Rectification matrix (identity)\n","    R = np.eye(3)\n","\n","    # Projection matrix for the undistorted image\n","    cpx = (image_width * S - 1) / 2\n","    cpy = (image_height * S - 1) / 2\n","    P = np.array([\n","        [f / mu, 0, cpx],\n","        [0, f / mu, cpy],\n","        [0, 0, 1]\n","    ])\n","\n","    return {\n","        \"K\": K,\n","        \"D\": D,\n","        \"R\": R,\n","        \"P\": P\n","    }\n","\n","# Parameters for the original image size (1920x1080)\n","fisheye_params = get_fisheye_params(image_width=1920, image_height=1080)\n","\n","# Output the parameters\n","print(\"Intrinsic Matrix (K):\\n\", fisheye_params[\"K\"])\n","print(\"Distortion Coefficients (D):\\n\", fisheye_params[\"D\"])\n","print(\"Rectification Matrix (R):\\n\", fisheye_params[\"R\"])\n","print(\"Projection Matrix (P):\\n\", fisheye_params[\"P\"])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X0_wQfwZkPar","executionInfo":{"status":"ok","timestamp":1731741664131,"user_tz":-330,"elapsed":1728,"user":{"displayName":"Yash Nahar","userId":"15294922963682605910"}},"outputId":"ea87f7cf-e1c4-42ab-9a53-d772879b1f3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Intrinsic Matrix (K):\n"," [[500.    0.  959.5]\n"," [  0.  500.  539.5]\n"," [  0.    0.    1. ]]\n","Distortion Coefficients (D):\n"," [ 0.01166363 -0.04819808  0.07918044 -0.037572  ]\n","Rectification Matrix (R):\n"," [[1. 0. 0.]\n"," [0. 1. 0.]\n"," [0. 0. 1.]]\n","Projection Matrix (P):\n"," [[5.0000e+02 0.0000e+00 1.9195e+03]\n"," [0.0000e+00 5.0000e+02 1.0795e+03]\n"," [0.0000e+00 0.0000e+00 1.0000e+00]]\n"]}]},{"cell_type":"code","source":["four_corners_and_centre = [(960, 540), (710,290), (1210,290), (710,790), (1210,790)]\n","\n","mapped_coords = []\n","for point in four_corners_and_centre:\n","    print(map_coordinates(coord=point, fisheye_params=fisheye_params))\n","    print(\"\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d70luJljruHJ","executionInfo":{"status":"ok","timestamp":1731749148710,"user_tz":-330,"elapsed":387,"user":{"displayName":"Yash Nahar","userId":"15294922963682605910"}},"outputId":"4c4c2845-ed37-4670-d160-dc8630118006"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'undistorted': (1920.0, 1080.0), 'crop_corrected': (320.0, 415.0)}\n","\n","\n","{'undistorted': (1618.8156, 778.8155), 'crop_corrected': (18.8155517578125, 113.81549072265625)}\n","\n","\n","{'undistorted': (2221.646, 778.56024), 'crop_corrected': (621.64599609375, 113.56024169921875)}\n","\n","\n","{'undistorted': (1618.5602, 1381.646), 'crop_corrected': (18.5601806640625, 716.64599609375)}\n","\n","\n","{'undistorted': (2221.9028, 1381.9027), 'crop_corrected': (621.90283203125, 716.9027099609375)}\n","\n","\n"]}]},{"cell_type":"code","source":["originals = [\n","    \"20170418/170418_175706_183328_frames/20170418_175706_frame_0.jpg\",\n","    \"20170418/170418_175706_183328_frames/20170418_175707_frame_60.jpg\",\n","    \"20170418/170418_175706_183328_frames/20170418_175708_frame_120.jpg\",\n","    \"20170418/170418_175706_183328_frames/20170418_175709_frame_180.jpg\",\n","    \"20170418/170418_175706_183328_frames/20170418_175710_frame_240.jpg\"\n","]\n","\n","original_images = [load_image_from_blob_cv(original, container_client) for original in originals]\n","fisheye_crr_images = [undistort_fisheye_image(original_image) for original_image in original_images]\n","crop_corrected_images = [crop_and_correct_image_cv2(corrected_image) for corrected_image in fisheye_crr_images]\n","grey_scale_images = [cv2.cvtColor(crop_corr_image, cv2.COLOR_RGB2GRAY) for crop_corr_image in crop_corrected_images]\n","augmented_images = [CN.augment_greyscale_image(grey_scale_image, contrast_factor=1.5, brightness_beta=30, kernel_size=(5, 5)) for grey_scale_image in grey_scale_images]\n","augmented_gbr_images = [cv2.cvtColor(cv2.cvtColor(augmented_image, cv2.COLOR_GRAY2RGB), cv2.COLOR_RGB2BGR) for augmented_image in augmented_images]"],"metadata":{"id":"Kq2dDwYPjJqX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["four_corners_and_centre = [(960, 540),\n","                (710,290),\n","                (1210,290),\n","                (710,790),\n","                (1210,790)]\n","\n","mapped_coords = []\n","for point in four_corners_and_centre:\n","    mapped_coords.append(map_coordinates2(coord=point, fisheye_params=fisheye_params))\n","print(mapped_coords)\n","\n","fig, axes = plt.subplots(len(originals), 6, figsize=(20, 20))\n","\n","for i, (original_image, fisheye_image, crop_corrected_image, grey_scale_image, augmented_image, augmented_gbr_image) in enumerate(zip(original_images, fisheye_crr_images, crop_corrected_images, grey_scale_images, augmented_images, augmented_gbr_images)):\n","    # Map coordinates to each image stage\n","    axes[i, 0].imshow(original_image)\n","    for point in four_corners_and_centre:\n","      axes[i, 0].plot(point[0], point[1], 'ro')\n","    axes[i, 0].set_title(f'original_image {i+1}')\n","    axes[i, 0].axis('off')\n","\n","    axes[i, 1].imshow(fisheye_image)\n","    for point in mapped_coords:\n","      axes[i, 1].plot(point[\"undistorted\"][0], point[\"undistorted\"][1], 'ro')\n","    axes[i, 1].set_title(f'undistorted_image {i+1}')\n","    axes[i, 1].axis('off')\n","\n","    axes[i, 2].imshow(crop_corrected_image)\n","    for point in mapped_coords:\n","      axes[i, 2].plot(point[\"crop_corrected\"][0], point[\"crop_corrected\"][1], 'ro')\n","    axes[i, 2].set_title(f'crop_corrected_image {i+1}')\n","    axes[i, 2].axis('off')\n","\n","    axes[i, 3].imshow(grey_scale_image, cmap='gray')\n","    for point in mapped_coords:\n","      axes[i, 3].plot(point[\"crop_corrected\"][0], point[\"crop_corrected\"][1], 'ro')\n","    axes[i, 3].set_title(f'grey_scale_image {i+1}')\n","    axes[i, 3].axis('off')\n","\n","    axes[i, 4].imshow(augmented_image, cmap='gray')\n","    for point in mapped_coords:\n","      axes[i, 4].plot(point[\"crop_corrected\"][0], point[\"crop_corrected\"][1], 'ro')\n","    axes[i, 4].set_title(f'augmented_image {i+1}')\n","    axes[i, 4].axis('off')\n","\n","    axes[i, 5].imshow(augmented_gbr_image)\n","    for point in mapped_coords:\n","      axes[i, 5].plot(point[\"crop_corrected\"][0], point[\"crop_corrected\"][1], 'ro')\n","    axes[i, 5].set_title(f'augmented_image {i+1}')\n","    axes[i, 5].axis('off')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1BscltfK6sM67qHqA9d8CKNoK9848Yv_Q"},"id":"_y9P1j2DjM2Q","executionInfo":{"status":"ok","timestamp":1731743935827,"user_tz":-330,"elapsed":17907,"user":{"displayName":"Yash Nahar","userId":"15294922963682605910"}},"outputId":"347736b1-4160-4acf-f293-59c04c10f5d6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["# Example coordinate in the crop-corrected image\n","four_corners_and_centre = [(400, 400), (0,0), (0,800), (800,0), (800,800)]\n","\n","unmapped_coords = []\n","\n","# Unmap the coordinates back to the original image\n","for point in four_corners_and_centre:\n","  unmapped_coords.append(unmap_coordinates2(\n","      crop_corrected_coord=point,\n","      original_size=(1920, 1080),\n","      fisheye_params=fisheye_params,\n","      crop_size1=(1500, 1500),\n","      crop_offset=(85, 180),\n","      crop_size2=(800, 800)\n","  ))\n","\n","print(\"Unmapped Coordinates:\")\n","print(unmapped_coords)\n","\n","fig, axes = plt.subplots(len(originals), 5, figsize=(20, 20))\n","\n","for i, (original_image, fisheye_image, crop_corrected_image, grey_scale_image, augmented_image) in enumerate(zip(original_images, fisheye_crr_images, crop_corrected_images, grey_scale_images, augmented_images)):\n","    # Map coordinates to each image stage\n","\n","    axes[i, 0].imshow(augmented_image, cmap='gray')\n","    for point in four_corners_and_centre:\n","      axes[i, 0].plot(point[0], point[1], 'ro')\n","    axes[i, 0].set_title(f'augmented_image {i+1}')\n","    axes[i, 0].axis('off')\n","\n","    axes[i, 1].imshow(grey_scale_image, cmap='gray')\n","    for point in four_corners_and_centre:\n","      axes[i, 1].plot(point[0], point[1], 'ro')\n","    axes[i, 1].set_title(f'grey_scale_image {i+1}')\n","    axes[i, 1].axis('off')\n","\n","    axes[i, 2].imshow(crop_corrected_image)\n","    for point in four_corners_and_centre:\n","      axes[i, 2].plot(point[0], point[1], 'ro')\n","    axes[i, 2].set_title(f'crop_corrected_image {i+1}')\n","    axes[i, 2].axis('off')\n","\n","    axes[i, 3].imshow(fisheye_image)\n","    for point in unmapped_coords:\n","      axes[i, 3].plot(point[\"undistorted\"][0], point[\"undistorted\"][1], 'ro')\n","    axes[i, 3].set_title(f'undistorted_image {i+1}')\n","    axes[i, 3].axis('off')\n","\n","    axes[i, 4].imshow(original_image)\n","    for point in unmapped_coords:\n","      axes[i, 4].plot(point[\"original\"][0], point[\"original\"][1], 'ro')\n","    axes[i, 4].set_title(f'original_image {i+1}')\n","    axes[i, 4].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1VASTWeFXXw4iuKhB5d6JV4qylmIcq5ld"},"id":"Gqp69wgs6poa","executionInfo":{"status":"ok","timestamp":1731743167063,"user_tz":-330,"elapsed":18633,"user":{"displayName":"Yash Nahar","userId":"15294922963682605910"}},"outputId":"b26abd26-5af0-47c5-ccba-1a5995a5c9e1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}