{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Frame Extraction and Other Video Processing Scripts"],"metadata":{"id":"vPA-ZTr_MXlo"}},{"cell_type":"code","source":["# !pip install azure-storage-blob tensorflow tensorflow-io av --quiet\n","!# pip install azure-identity --quiet\n","\n","try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","!pip install tensorflow-io"],"metadata":{"id":"gfHmd6b4MiMw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727061191935,"user_tz":240,"elapsed":6523,"user":{"displayName":"Christina Wang","userId":"02048582006442704762"}},"outputId":"9ea6573b-d20e-4224-960d-fe8628903c8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n","Collecting tensorflow-io\n","  Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.37.1)\n","Downloading tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tensorflow-io\n","Successfully installed tensorflow-io-0.37.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/harvard.dce.nasa.cloud2cloud"],"metadata":{"id":"jeahQuWnSNN6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727061192731,"user_tz":240,"elapsed":799,"user":{"displayName":"Christina Wang","userId":"02048582006442704762"}},"outputId":"d9035092-f40a-4b56-e2b8-5a3869671c78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/.shortcut-targets-by-id/1DZ81MWvJaMALBYDX54JddfVO9g-pLLu-/harvard.dce.nasa.cloud2cloud\n"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","\n","account_name = userdata.get('storage_account_name')\n","account_key = userdata.get('storage_account_key')\n","container_name = userdata.get('blob_container_name')"],"metadata":{"id":"3zi4_x9tM_FM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Set-up environment variable for TFIO connection\n","import os\n","import tensorflow as tf\n","import tensorflow_io as tfio\n","import pandas as pd\n","\n","os.environ['TF_AZURE_STORAGE_KEY'] = account_key\n","\n","output_foldername = \"processed_v1\"\n","pathname = f'az://{account_name}/{container_name}/{output_foldername}'\n","\n","# list files and directories in container named ''\n","current_dirs_azure = tf.io.gfile.listdir(f'az://{account_name}/{container_name}')\n","\n","# create dir in azure storage container\n","if pathname in current_dirs_azure:\n","  print(\"path already exists\")\n","else:\n","  tf.io.gfile.mkdir(pathname)\n","  print(\"directory created\")"],"metadata":{"id":"mUNBlA8fNC4e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727061202375,"user_tz":240,"elapsed":892,"user":{"displayName":"Christina Wang","userId":"02048582006442704762"}},"outputId":"056ff97e-698d-4e26-fb36-f5b939c21f0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["directory created in Azure:  az://nasacloud/nasablob/processed_v1\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.dates as mdates\n","import pandas as pd\n","import numpy as np\n","import os\n","import io\n","import cv2\n","import tensorflow as tf\n","import tensorflow_io as tfio\n","#import av\n","import time\n","import shutil\n","import datetime"],"metadata":{"id":"b3EeRUrBMg4y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8ec-83xIx_d"},"outputs":[],"source":["# def delete_tmp_file(file_path, type):\n","#     \"\"\"\n","#     Deletes the tmp file from drive.\n","#     Args:\n","#       file_path (str): path to the file to be deleted.\n","#     \"\"\"\n","#     if type == \"file\":\n","#       if os.path.exists(file_path):\n","#           os.remove(file_path)\n","#       else:\n","#         print(f\"File not found: {file_path}\")\n","#     elif type == \"dir\":\n","#       if os.path.exists(file_path):\n","#           shutil.rmtree(file_path)\n","#       else:\n","#         print(f\"File not found: {file_path}\")\n","\n","\n","# def download_blob_to_temp(video_path, blob_client):\n","#     \"\"\"\n","#     Download a blob from azure to tmp dir in google dir.\n","#     Args:\n","#       video_path (str): path to the video blob.\n","#     Returns:\n","#       (str): path to tmp local video file\n","#     \"\"\"\n","#     local_video_path = f'/tmp/{os.path.basename(video_path)}'\n","#     with open(local_video_path, \"wb\") as file:\n","#         data = blob_client.download_blob().readall()\n","#         file.write(data)\n","#     return local_video_path\n","\n","\n","def upload_frames_to_blob(frames_folder, blob_dir, container_client):\n","    \"\"\"\n","    Upload extracted frames from drive to azure blob.\n","    Args:\n","        frames_folder (str): path to folder holding the frames\n","        blob_dir (str): blob where frames are to be uploaded\n","        container_client (azure.storage.blob.ContainerClient): azure blob storage container client\n","    Returns:\n","      None\n","    \"\"\"\n","    for frame in os.listdir(frames_folder):\n","        frame_path = os.path.join(frames_folder, frame)\n","        blob_name = f\"{blob_dir}/{frame}\"\n","        blob_client = container_client.get_blob_client(blob_name)\n","        with open(frame_path, \"rb\") as data:\n","            blob_client.upload_blob(data, overwrite=True)\n","\n","def extract_frames(video_path, frame_rate):\n","    \"\"\"\n","    Extract frames from video at a specified frame rate per second and upload them to blob storage.\n","\n","    Args:\n","      video_path (str): path to the video blob in azure\n","      frame_rate (int): no of frames per second\n","\n","    Returns:\n","      (string): o/p folder in the azure blob where frames are uploaded.\n","    \"\"\"\n","\n","    # blob_client = container_client.get_blob_client(video_path)\n","    # blob_dir = f\"{os.path.splitext(video_path)[0]}_frames\"\n","    # print(blob_dir)\n","    # blob_list = container_client.list_blobs(name_starts_with=blob_dir)\n","    # print(blob_list)\n","    # if any(blob_list):\n","    #     print(\"blob already exists, skipping frame extraction.\")\n","    #     return f\"skipped {video_path}\"\n","\n","    # local tmp storage\n","    #local_video_path = download_blob_to_temp(video_path, blob_client)\n","    local_video_path = f'/tmp/{os.path.basename(video_path)}'\n","    filename = os.path.basename(local_video_path)\n","    date = filename[:6]\n","    start_time_str = filename[7:13]\n","    video_start_time = datetime.datetime.strptime(f\"20{date} {start_time_str}\", \"%Y%m%d %H%M%S\")\n","    #folder_name = f\"/tmp/{os.path.join(os.path.dirname(video_path), os.path.splitext(filename)[0] + '_frames')}\"\n","\n","    # # create a folder to store extracted frames\n","    # if not os.path.exists(folder_name):\n","    #     os.makedirs(folder_name)\n","\n","    pathname = f'az://{account_name}/{container_name}/{video_path}'\n","\n","    with tf.io.gfile.GFile(pathname, mode='r') as r:\n","      r.read()\n","\n","\n","    # cap = cv2.VideoCapture(local_video_path)\n","    # if not cap.isOpened():\n","    #     print(\"Error during video load.\")\n","    #     return\n","\n","    # fps = cap.get(cv2.CAP_PROP_FPS)\n","    # total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    # video_duration = total_frames / fps\n","\n","    # frame_interval = int(fps / frame_rate)\n","\n","    # # extract frames\n","    # count = 0\n","    # for frame_number in range(0, total_frames, frame_interval):\n","    #     cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n","    #     ret, frame = cap.read()\n","    #     if not ret:\n","    #         print(f\"Error: Unable to read frame {frame_number}.\")\n","    #         continue\n","\n","    #     frame_time = video_start_time + datetime.timedelta(seconds=frame_number / fps)\n","    #     img_filename = os.path.join(folder_name, f\"{frame_time.strftime('%Y%m%d_%H%M%S')}_frame_{frame_number}.jpg\")\n","    #     cv2.imwrite(img_filename, frame)\n","    #     count += 1\n","\n","    # cap.release()\n","\n","    # # upload extracted frames to azure blob and return blob directory\n","    # upload_frames_to_blob(folder_name, blob_dir, container_client)\n","\n","    # # delete tmp files\n","    # delete_tmp_file(local_video_path, \"file\")\n","    # delete_tmp_file(folder_name, \"dir\")\n","\n","    return blob_dir"]},{"cell_type":"code","source":["video_path = \"20170418/170418_175706_183328.avi\"\n","frame_rate = 1\n","output_folder = extract_frames(video_path, frame_rate)\n","print(f\"Frames saved to {output_folder} in Azure Blob Storage\")"],"metadata":{"id":"aeTT5dkEMrPc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["frame_rate = 1\n","blob_list = container_client.list_blobs(name_starts_with=\"20170422/\")\n","for blob in blob_list:\n","    if blob.name.endswith('.avi'):\n","      print(f\"Name: {blob.name}\")\n","      output_folder = extract_frames(blob.name, 1)\n","      print(f\"Frames saved to {output_folder} in Azure Blob Storage\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uII18O7M1Cu","outputId":"34eea2a4-86fc-42b0-fa3c-fbd3c03eef3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: 20170422/170422_203040_210703.avi\n","20170422/170422_203040_210703_frames\n","<iterator object azure.core.paging.ItemPaged at 0x7e64971dd9c0>\n","Frames saved to 20170422/170422_203040_210703_frames in Azure Blob Storage\n","Name: 20170422/170422_210704_212527.avi\n","20170422/170422_210704_212527_frames\n","<iterator object azure.core.paging.ItemPaged at 0x7e64971ddd80>\n","Frames saved to 20170422/170422_210704_212527_frames in Azure Blob Storage\n","Name: 20170422/170422_212816_215538.avi\n","20170422/170422_212816_215538_frames\n","<iterator object azure.core.paging.ItemPaged at 0x7e64971dfa60>\n"]}]}]}